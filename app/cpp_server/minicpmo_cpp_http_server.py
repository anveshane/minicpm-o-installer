"""
MiniCPMO C++ åç«¯ HTTP æœåŠ¡å™¨ï¼ˆç»Ÿä¸€ç‰ˆï¼šæ”¯æŒå•å·¥/åŒå·¥æ¨¡å¼åˆ‡æ¢ï¼‰
é€šè¿‡ HTTP æ¥å£åŒ…è£… C++ llama-server çš„åŠŸèƒ½ï¼Œå¯¹å¤–æä¾›ä¸ Python ç‰ˆæœ¬ä¸€è‡´çš„ API

æ¨¡å¼è¯´æ˜ï¼š
- å•å·¥æ¨¡å¼ (duplex_mode=False): ä½¿ç”¨"å»¶è¿Ÿä¸€æ‹"æœºåˆ¶ï¼Œæ¯ä¸ª round æœ‰ç‹¬ç«‹ç›®å½•
- åŒå·¥æ¨¡å¼ (duplex_mode=True): ç›´æ¥è½¬å‘ prefillï¼Œå…¨å±€ WAV è®¡æ•°å™¨ï¼Œæ”¯æŒå¹¶è¡Œå¤„ç†
"""
import os
import sys
import base64
import json
import asyncio
import io
import librosa
import numpy as np
import soundfile as sf
from PIL import Image
from contextlib import asynccontextmanager
from typing import Optional, List, Dict, Any
from datetime import datetime
from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
import subprocess
import signal
import time
import httpx
import socket
import requests
import threading
from http.server import HTTPServer, BaseHTTPRequestHandler
import uuid
import shutil

# ====================== é…ç½® ======================
# æ³¨æ„: Python Token2Wav ç°åœ¨ç”± C++ ç¨‹åºç›´æ¥é€šè¿‡ subprocess è°ƒç”¨
# C++ t2w_thread ä¼šå¯åŠ¨ Python æœåŠ¡è¿›ç¨‹å¤„ç† audio tokens å¹¶ç”Ÿæˆ WAV æ–‡ä»¶
# HTTP server åªéœ€è¦è¯»å– tts_wav ç›®å½•ä¸‹çš„ WAV æ–‡ä»¶å³å¯ï¼ˆå’Œä¹‹å‰ä¸€æ ·ï¼‰
# C++ æœåŠ¡å™¨é…ç½®
CPP_SERVER_HOST = "127.0.0.1"
# C++ ç«¯å£åŠ¨æ€è®¡ç®—ï¼šPython ç«¯å£ + 10000ï¼Œä¾‹å¦‚ 8100 -> 18100
CPP_SERVER_PORT = None  # åœ¨ lifespan ä¸­æ ¹æ® Python ç«¯å£è®¾ç½®
CPP_SERVER_URL = None   # åœ¨ lifespan ä¸­æ ¹æ® Python ç«¯å£è®¾ç½®

# æ¨¡å‹é…ç½® - å¿…é¡»é€šè¿‡ç¯å¢ƒå˜é‡æˆ–å‘½ä»¤è¡Œå‚æ•°æŒ‡å®š
# ğŸ”§ [æœ¬åœ°éƒ¨ç½²] å¿…é¡»è®¾ç½® LLAMACPP_ROOT å’Œ MODEL_DIR
LLAMACPP_ROOT = os.environ.get("LLAMACPP_ROOT", "")  # å¿…é¡»æŒ‡å®š
DEFAULT_MODEL_DIR = os.environ.get("MODEL_DIR", "")  # å¿…é¡»æŒ‡å®š
DEFAULT_LLM_MODEL = os.environ.get("LLM_MODEL", "")  # å¦‚æœä¸æŒ‡å®šï¼Œè‡ªåŠ¨ä» MODEL_DIR æŸ¥æ‰¾
# GPU è®¾å¤‡ï¼šmacOS ä½¿ç”¨ Metalï¼ˆè®¾ä¸ºç©ºå­—ç¬¦ä¸²ï¼‰ï¼ŒLinux/CUDA ä½¿ç”¨è®¾å¤‡ID
DEFAULT_GPU_DEVICES = os.environ.get("CUDA_VISIBLE_DEVICES", "")
DEFAULT_CTX_SIZE = int(os.environ.get("CTX_SIZE", "8192"))
DEFAULT_N_GPU_LAYERS = int(os.environ.get("N_GPU_LAYERS", "99"))

# å›ºå®šéŸ³è‰²æ–‡ä»¶ï¼ˆç”¨äº voice cloningï¼‰
FIXED_TIMBRE_PATH = os.environ.get("REF_AUDIO", "")  # é»˜è®¤åœ¨å¯åŠ¨æ—¶ä» LLAMACPP_ROOT æ¨å¯¼

# è§†è§‰ç¼–ç å™¨åç«¯: "metal"(é»˜è®¤ï¼ŒGPU) æˆ– "coreml"(ANEåŠ é€Ÿï¼ŒmacOSä¸“ç”¨)
VISION_BACKEND = os.environ.get("VISION_BACKEND", "metal")

# Token2Wav device: "gpu:1"(é»˜è®¤ï¼ŒGPUåŠ é€Ÿ) æˆ– "cpu"(èŠ‚çœGPUæ˜¾å­˜ï¼Œé€‚åˆ16GBå†…å­˜æœºå‹)
TOKEN2WAV_DEVICE = os.environ.get("TOKEN2WAV_DEVICE", "gpu:1")


def auto_detect_llm_model(model_dir: str) -> str:
    """è‡ªåŠ¨ä»æ¨¡å‹ç›®å½•æ£€æµ‹ LLM GGUF æ–‡ä»¶
    
    ä¼˜å…ˆçº§ï¼šQ4_K_M > Q8_0 > F16 > å…¶ä»– .gguf æ–‡ä»¶
    """
    if not model_dir or not os.path.isdir(model_dir):
        return ""
    
    # æŒ‰ä¼˜å…ˆçº§æ’åºçš„æ¨¡å¼
    priority_patterns = [
        "*Q4_K_M*.gguf",
        "*Q4_K_S*.gguf", 
        "*Q8_0*.gguf",
        "*Q5_K_M*.gguf",
        "*F16*.gguf",
    ]
    
    import glob
    
    # æŒ‰ä¼˜å…ˆçº§æŸ¥æ‰¾
    for pattern in priority_patterns:
        matches = glob.glob(os.path.join(model_dir, pattern))
        # æ’é™¤å­ç›®å½•ä¸­çš„æ–‡ä»¶ï¼Œåªå–æ ¹ç›®å½•çš„
        root_matches = [m for m in matches if os.path.dirname(m) == model_dir]
        if root_matches:
            # è¿”å›æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„ï¼‰
            return os.path.basename(sorted(root_matches)[0])
    
    # å¦‚æœä¼˜å…ˆæ¨¡å¼éƒ½æ²¡æ‰¾åˆ°ï¼ŒæŸ¥æ‰¾ä»»æ„ .gguf æ–‡ä»¶
    all_gguf = glob.glob(os.path.join(model_dir, "*.gguf"))
    if all_gguf:
        # æ’é™¤æ˜æ˜¾ä¸æ˜¯ LLM çš„æ–‡ä»¶ï¼ˆå¦‚ audio, vision, ttsï¼‰
        llm_candidates = [f for f in all_gguf 
                         if not any(x in os.path.basename(f).lower() 
                                   for x in ['audio', 'vision', 'tts', 'projector'])]
        if llm_candidates:
            return os.path.basename(sorted(llm_candidates)[0])
    
    return ""

# ä¸´æ—¶æ–‡ä»¶ç›®å½•
TEMP_DIR = os.path.join(os.path.dirname(__file__), "temp_streaming_prefill")

# C++ llama-server è¾“å‡ºç›®å½• (tools/omni/output)
# ğŸ”§ [å¤šå®ä¾‹æ”¯æŒ] é»˜è®¤å€¼ï¼Œè¿è¡Œæ—¶å¯é€šè¿‡ --output-dir å‚æ•°è¦†ç›–
DEFAULT_CPP_OUTPUT_DIR = os.path.join(LLAMACPP_ROOT, "tools/omni/output")
CPP_OUTPUT_DIR = DEFAULT_CPP_OUTPUT_DIR  # è¿è¡Œæ—¶ä¼šè¢«æ›¿æ¢ä¸ºå®é™…å€¼

# æœåŠ¡æ³¨å†Œé…ç½®ï¼ˆé»˜è®¤ä¸ºæœ¬æœº IP:8025 ç«¯å£ï¼Œè®¾ä¸ºç©ºåˆ™ä¸æ³¨å†Œï¼‰
# ğŸ”§ [æœ¬åœ°è”è°ƒ] åŠ¨æ€è·å–æœ¬æœº IPï¼Œæ³¨å†Œåˆ°åç«¯æœåŠ¡ 8025 ç«¯å£ï¼ˆé¿å… macOS 8021 ç«¯å£å†²çªï¼‰
def _get_default_register_url():
    """è·å–é»˜è®¤æ³¨å†Œåœ°å€ï¼ˆæœ¬æœº IP:8025ï¼‰"""
    try:
        import socket
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        s.connect(('8.8.8.8', 80))
        local_ip = s.getsockname()[0]
        s.close()
        return f"http://{local_ip}:8025"
    except:
        return "http://127.0.0.1:8025"

REGISTER_URL = os.environ.get("REGISTER_URL", _get_default_register_url())

# ====================== å…¨å±€çŠ¶æ€ ======================
cpp_server_process: Optional[subprocess.Popen] = None
current_msg_type: Optional[int] = None  # 1=audio, 2=video/omni
current_duplex_mode: bool = False  # æ˜¯å¦å¯ç”¨åŒå·¥æ¨¡å¼
current_high_quality_mode: bool = False  # æ˜¯å¦å¯ç”¨é«˜æ¸…æ¨¡å¼ï¼ˆmax_slice_nums=2ï¼‰
current_high_fps_mode: bool = False  # æ˜¯å¦å¯ç”¨é«˜åˆ·æ¨¡å¼ï¼ˆ1ç§’5å¸§stackï¼‰
current_active_session_id: Optional[str] = None
current_request_counter: int = 0
current_round_number: int = 0
session_lock = threading.Lock()
model_state_initialized: bool = False
pending_prefill_data: Optional[dict] = None
is_breaking: bool = False  # break æ ‡å¿—ï¼šä¸º True æ—¶ä¸­é—´å±‚åœæ­¢å‘å‰ç«¯å‘é€æ•°æ®
health_server_thread: Optional[threading.Thread] = None

# ğŸ”§ [é«˜åˆ·æ¨¡å¼] å­å›¾ç¼“å­˜ï¼šæŒ‰ image_audio_id åˆ†ç»„å­˜å‚¨ï¼ˆframe_index 1-4 çš„å­å›¾ï¼‰
# key: image_audio_id, value: {frame_index: PIL.Image}
# æ³¨æ„ï¼šä¸»å›¾ï¼ˆframe_index=0ï¼‰ç«‹å³å¤„ç†ï¼Œä¸ç¼“å­˜
high_fps_subimage_cache: Dict[int, Dict[int, Image.Image]] = {}
high_fps_cache_lock = threading.Lock()
# ğŸ”§ [é«˜åˆ·æ¨¡å¼] å¾…å¤„ç†éŸ³é¢‘ç¼“å­˜ï¼šå½“éŸ³é¢‘å…ˆäºå­å›¾åˆ°è¾¾æ—¶æš‚å­˜
# key: image_audio_id, value: (audio_np, sr, audio_path)
high_fps_pending_audio: Dict[int, tuple] = {}
high_fps_audio_lock = threading.Lock()

# ğŸ”§ [åŒå·¥æ¨¡å¼] å…¨å±€ WAV å‘é€è®¡æ•°å™¨ï¼ˆè·¨ generate è°ƒç”¨ä¿æŒçŠ¶æ€ï¼‰
global_sent_wav_count: int = 0
# å…¨å±€æ–‡æœ¬è¡Œè®¡æ•°å™¨ï¼ˆè·¨ generate è°ƒç”¨ä¿æŒçŠ¶æ€ï¼Œç”¨äºç´¯ç§¯è§£æ llm_text.txtï¼‰
global_parsed_line_count: int = 0
# å…¨å±€æ–‡æœ¬åˆ—è¡¨ï¼ˆè·¨ generate è°ƒç”¨ä¿æŒçŠ¶æ€ï¼‰
global_parsed_texts: list = []
# å…¨å±€æ–‡æœ¬å‘é€ç´¢å¼•ï¼ˆå·²å‘é€çš„æ–‡æœ¬æ•°é‡ï¼Œç”¨äºé¡ºåºæ¶ˆè´¹æ–‡æœ¬ï¼‰
global_text_send_idx: int = 0
# ğŸ”§ [ä¿®å¤å›æ–‡] å…¨å±€å·²å‘é€ WAV æ–‡ä»¶åé›†åˆï¼ˆè·¨ generate è°ƒç”¨ä¿æŒçŠ¶æ€ï¼‰
global_sent_wav_files: set = set()

# WAV å‘é€æ—¶åºæ—¥å¿—
WAV_TIMING_LOG_PATH = os.path.join(os.path.dirname(__file__), "wav_timing.log")
wav_timing_log_file: Optional[Any] = None  # å…¨å±€æ—¥å¿—æ–‡ä»¶å¥æŸ„
last_wav_send_time: Optional[float] = None  # ä¸Šä¸€æ¬¡ WAV å‘é€æ—¶é—´

# HTTP å®¢æˆ·ç«¯
http_client: Optional[httpx.AsyncClient] = None

# ====================== æ˜¾å­˜ç›‘æ§é…ç½® ======================
GPU_MEMORY_THRESHOLD_MB = 2000  # æ˜¾å­˜å‰©ä½™ä½äºæ­¤å€¼æ—¶è§¦å‘é‡å¯ (MB)
# ğŸ”§ [æœ¬åœ°éƒ¨ç½²] é»˜è®¤ç¦ç”¨æ˜¾å­˜æ£€æŸ¥å’Œè‡ªåŠ¨é‡å¯åŠŸèƒ½ï¼ˆç”Ÿäº§ç¯å¢ƒå¯é€šè¿‡ç¯å¢ƒå˜é‡å¯ç”¨ï¼‰
# è®¾ç½® GPU_MEMORY_CHECK=1 å¯ç”¨æ˜¾å­˜ç›‘æ§å’Œè‡ªåŠ¨é‡å¯
import platform
GPU_CHECK_ENABLED = os.environ.get("GPU_MEMORY_CHECK", "0") == "1"
cpp_restart_lock = threading.Lock()  # é‡å¯é”ï¼Œé˜²æ­¢å¹¶å‘é‡å¯
cpp_restarting = False  # ğŸ”§ [ä¿®å¤] æ­£åœ¨é‡å¯æ ‡å¿—ï¼Œé˜²æ­¢é‡å¯æœŸé—´æ¥æ”¶æ–°è¯·æ±‚


def get_gpu_memory_info() -> dict:
    """è·å– GPU æ˜¾å­˜ä¿¡æ¯
    
    Returns:
        dict: {
            'total_mb': æ€»æ˜¾å­˜ (MB),
            'used_mb': å·²ç”¨æ˜¾å­˜ (MB),
            'free_mb': å‰©ä½™æ˜¾å­˜ (MB),
            'utilization': ä½¿ç”¨ç‡ (0-100)
        }
        å¦‚æœè·å–å¤±è´¥è¿”å› None
    """
    try:
        import subprocess
        # ä½¿ç”¨ nvidia-smi è·å–æ˜¾å­˜ä¿¡æ¯
        gpu_id = os.environ.get("CUDA_VISIBLE_DEVICES", "0").split(",")[0]
        result = subprocess.run(
            ["nvidia-smi", "--query-gpu=memory.total,memory.used,memory.free", 
             "--format=csv,noheader,nounits", f"--id={gpu_id}"],
            capture_output=True, text=True, timeout=5
        )
        if result.returncode == 0:
            parts = result.stdout.strip().split(",")
            if len(parts) >= 3:
                total = int(parts[0].strip())
                used = int(parts[1].strip())
                free = int(parts[2].strip())
                return {
                    'total_mb': total,
                    'used_mb': used,
                    'free_mb': free,
                    'utilization': round(used / total * 100, 1) if total > 0 else 0
                }
    except Exception as e:
        print(f"[æ˜¾å­˜ç›‘æ§] è·å–æ˜¾å­˜ä¿¡æ¯å¤±è´¥: {e}", flush=True)
    return None


def check_gpu_memory_and_restart_if_needed() -> bool:
    """æ£€æŸ¥ GPU æ˜¾å­˜ï¼Œå¦‚æœå‰©ä½™ä¸è¶³åˆ™é‡å¯ C++ æœåŠ¡å™¨
    
    Returns:
        bool: True å¦‚æœæ‰§è¡Œäº†é‡å¯ï¼ŒFalse å¦‚æœä¸éœ€è¦é‡å¯
    """
    global cpp_server_process, model_state_initialized
    
    if not GPU_CHECK_ENABLED:
        return False
    
    mem_info = get_gpu_memory_info()
    if mem_info is None:
        return False
    
    free_mb = mem_info['free_mb']
    print(f"[æ˜¾å­˜ç›‘æ§] å‰©ä½™æ˜¾å­˜: {free_mb} MB (é˜ˆå€¼: {GPU_MEMORY_THRESHOLD_MB} MB)", flush=True)
    
    if free_mb < GPU_MEMORY_THRESHOLD_MB:
        print(f"[æ˜¾å­˜ç›‘æ§] âš ï¸ æ˜¾å­˜ä¸è¶³ ({free_mb} MB < {GPU_MEMORY_THRESHOLD_MB} MB)ï¼Œå‡†å¤‡é‡å¯ C++ æœåŠ¡å™¨...", flush=True)
        
        with cpp_restart_lock:
            # å†æ¬¡æ£€æŸ¥ï¼Œé¿å…é‡å¤é‡å¯
            mem_info = get_gpu_memory_info()
            if mem_info and mem_info['free_mb'] >= GPU_MEMORY_THRESHOLD_MB:
                print(f"[æ˜¾å­˜ç›‘æ§] æ˜¾å­˜å·²æ¢å¤ï¼Œå–æ¶ˆé‡å¯", flush=True)
                return False
            
            try:
                restart_cpp_server()
                return True
            except Exception as e:
                print(f"[æ˜¾å­˜ç›‘æ§] é‡å¯å¤±è´¥: {e}", flush=True)
                return False
    
    return False


def restart_cpp_server():
    """é‡å¯ C++ llama-serverï¼ˆä¿æŒç›¸åŒé…ç½®ï¼‰"""
    global cpp_server_process, model_state_initialized, current_msg_type
    global current_round_number, global_sent_wav_count, global_parsed_line_count
    global global_parsed_texts, global_text_send_idx, global_sent_wav_files
    global current_duplex_mode, cpp_restarting
    
    print("=" * 60, flush=True)
    print("[é‡å¯] å¼€å§‹é‡å¯ C++ llama-server...", flush=True)
    print("=" * 60, flush=True)
    
    # ğŸ”§ [ä¿®å¤] è®¾ç½®é‡å¯æ ‡å¿—ï¼Œé˜»æ­¢æ–°è¯·æ±‚
    cpp_restarting = True
    
    # ä¿å­˜å½“å‰æ¨¡å¼ï¼ˆé‡å¯åéœ€è¦æ¢å¤ï¼‰
    saved_duplex_mode = current_duplex_mode
    saved_msg_type = current_msg_type if current_msg_type else 2  # é»˜è®¤ omni æ¨¡å¼
    
    # 1. åœæ­¢å½“å‰ C++ æœåŠ¡å™¨
    stop_cpp_server()
    
    # 2. ç­‰å¾…è¿›ç¨‹å®Œå…¨é€€å‡º
    time.sleep(2)
    
    # 3. æ¸…ç† output ç›®å½•
    reset_output_dir()
    
    # 4. é‡ç½®çŠ¶æ€
    model_state_initialized = False
    current_msg_type = None
    current_round_number = 0
    global_sent_wav_count = 0
    global_parsed_line_count = 0
    global_parsed_texts = []
    global_text_send_idx = 0
    global_sent_wav_files = set()
    
    # 5. é‡æ–°å¯åŠ¨ C++ æœåŠ¡å™¨
    start_cpp_server(
        model_dir=app.state.model_dir,
        gpu_devices=app.state.gpu_devices,
        port=CPP_SERVER_PORT
    )
    
    print("[é‡å¯] C++ llama-server é‡å¯å®Œæˆ", flush=True)
    
    # 6. ğŸ”§ é‡æ–°åˆå§‹åŒ– omni contextï¼ˆè§£å†³é‡å¯å "omni context not initialized" çš„é—®é¢˜ï¼‰
    try:
        print("[é‡å¯] é‡æ–°åˆå§‹åŒ– omni context...", flush=True)
        
        model_dir = app.state.model_dir
        # TTS æ¨¡å‹åœ¨ tts/ ç›®å½•ï¼ŒToken2Wav æ¨¡å‹åœ¨ token2wav-gguf/ ç›®å½•
        tts_bin_dir = os.path.join(model_dir, "tts")
        
        cpp_request = {
            "media_type": saved_msg_type,      # æ¢å¤ä¹‹å‰çš„æ¨¡å¼
            "use_tts": True,
            "duplex_mode": saved_duplex_mode,
            "model_dir": model_dir,
            "tts_bin_dir": tts_bin_dir,
            "tts_gpu_layers": 100,
            "token2wav_device": TOKEN2WAV_DEVICE,
            "output_dir": CPP_OUTPUT_DIR,
        }
        
        # è§†è§‰ç¼–ç å™¨åç«¯
        cpp_request["vision_backend"] = VISION_BACKEND
        
        # ä½¿ç”¨å›ºå®šéŸ³è‰²æ–‡ä»¶
        if os.path.exists(FIXED_TIMBRE_PATH):
            cpp_request["voice_audio"] = FIXED_TIMBRE_PATH
        
        # ä½¿ç”¨åŒæ­¥ requestsï¼ˆå› ä¸ºå½“å‰åœ¨åå°çº¿ç¨‹ä¸­ï¼‰
        resp = requests.post(
            f"{CPP_SERVER_URL}/v1/stream/omni_init",
            json=cpp_request,
            timeout=60.0
        )
        
        if resp.status_code == 200:
            model_state_initialized = True
            current_msg_type = saved_msg_type
            current_duplex_mode = saved_duplex_mode
            print(f"[é‡å¯] omni context åˆå§‹åŒ–æˆåŠŸ: {resp.json()}", flush=True)
        else:
            print(f"[é‡å¯] omni context åˆå§‹åŒ–å¤±è´¥: {resp.text}", flush=True)
    except Exception as e:
        print(f"[é‡å¯] omni context åˆå§‹åŒ–å¼‚å¸¸: {e}", flush=True)
    finally:
        # ğŸ”§ [ä¿®å¤] æ— è®ºæˆåŠŸå¤±è´¥ï¼Œéƒ½æ¸…é™¤é‡å¯æ ‡å¿—
        cpp_restarting = False
    
    print("=" * 60, flush=True)


def stack_images(images: List[Image.Image]) -> Image.Image:
    """å°†å¤šå¼ å›¾ç‰‡ stack æˆä¸€å¼ 
    
    Stack ç­–ç•¥ï¼ˆæ ¹æ®å›¾ç‰‡æ•°é‡ï¼‰ï¼š
    - 1å¼ ï¼šç›´æ¥è¿”å›
    - 2å¼ ï¼šæ¨ªå‘æ‹¼æ¥ (1x2)
    - 3å¼ ï¼š2x2 å¸ƒå±€ï¼Œå³ä¸‹è§’ç©ºç™½
    - 4å¼ ï¼š2x2 å¸ƒå±€
    
    Args:
        images: PIL Image åˆ—è¡¨
        
    Returns:
        æ‹¼æ¥åçš„å•å¼  PIL Image
    """
    if len(images) == 0:
        raise ValueError("images åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
    if len(images) == 1:
        return images[0]
    
    # è·å–å•å¼ å›¾ç‰‡å°ºå¯¸ï¼ˆå‡è®¾æ‰€æœ‰å›¾ç‰‡å°ºå¯¸ç›¸åŒï¼‰
    w, h = images[0].size
    
    if len(images) == 2:
        # æ¨ªå‘æ‹¼æ¥ 1x2
        result = Image.new('RGB', (w * 2, h))
        result.paste(images[0], (0, 0))
        result.paste(images[1], (w, 0))
    elif len(images) == 3:
        # 2x2 å¸ƒå±€ï¼Œå³ä¸‹è§’ç©ºç™½ï¼ˆé»‘è‰²ï¼‰
        result = Image.new('RGB', (w * 2, h * 2), (0, 0, 0))
        result.paste(images[0], (0, 0))
        result.paste(images[1], (w, 0))
        result.paste(images[2], (0, h))
    else:  # 4å¼ æˆ–æ›´å¤šï¼ˆå–å‰4å¼ ï¼‰
        # 2x2 å¸ƒå±€
        result = Image.new('RGB', (w * 2, h * 2))
        result.paste(images[0], (0, 0))
        result.paste(images[1], (w, 0))
        result.paste(images[2], (0, h))
        if len(images) >= 4:
            result.paste(images[3], (w, h))
    
    return result


class HealthCheckHandler(BaseHTTPRequestHandler):
    """ç‹¬ç«‹çš„å¥åº·æ£€æŸ¥å’Œæ‰“æ–­HTTPå¤„ç†å™¨ï¼Œè¿è¡Œåœ¨å•ç‹¬çº¿ç¨‹ä¸­ï¼Œä¸å—ä¸»çº¿ç¨‹æ¨ç†ä»»åŠ¡é˜»å¡
    
    æ”¯æŒçš„æ¥å£ï¼š
    - GET /health - å¥åº·æ£€æŸ¥
    - POST /omni/break - æ‰“æ–­å½“å‰ç”Ÿæˆï¼ˆå¿«é€Ÿå“åº”ï¼Œä¸é˜»å¡ï¼‰
    - POST /omni/stop - åœæ­¢ä¼šè¯ï¼ˆå¿«é€Ÿå“åº”ï¼Œä¸é˜»å¡ï¼‰
    """
    
    def log_message(self, format, *args):
        """ç¦ç”¨é»˜è®¤æ—¥å¿—è¾“å‡ºï¼Œé¿å…å¹²æ‰°ä¸»ç¨‹åºæ—¥å¿—"""
        pass
    
    def do_GET(self):
        if self.path == "/health" or self.path == "/":
            self.send_response(200)
            self.send_header("Content-Type", "application/json")
            self.send_header("Access-Control-Allow-Origin", "*")
            self.end_headers()
            response = json.dumps({
                "status": "healthy",
                "message": "æœåŠ¡æ­£å¸¸ (C++ backend)",
                "backend": "cpp"
            })
            self.wfile.write(response.encode())
        else:
            self.send_response(404)
            self.end_headers()
    
    def do_POST(self):
        """å¤„ç† POST è¯·æ±‚ - æ‰“æ–­å’Œåœæ­¢"""
        global is_breaking, CPP_SERVER_URL
        
        if self.path == "/omni/break":
            # å¿«é€Ÿæ‰“æ–­ - åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­è®¾ç½® break æ ‡å¿—å¹¶è°ƒç”¨ C++ break æ¥å£
            print("======= [ç‹¬ç«‹çº¿ç¨‹] æ”¶åˆ°å¿«é€Ÿæ‰“æ–­æŒ‡ä»¤ =======", flush=True)
            
            # ã€å…³é”®ã€‘ç«‹å³è®¾ç½® break æ ‡å¿—ï¼Œè®© generate_stream åœæ­¢å‘å‰ç«¯å‘é€æ•°æ®
            is_breaking = True
            print("[ç‹¬ç«‹çº¿ç¨‹] is_breaking å·²è®¾ç½®ä¸º Trueï¼Œä¸­é—´å±‚å°†åœæ­¢å‘é€æ•°æ®", flush=True)
            
            # è°ƒç”¨ C++ æœåŠ¡å™¨çš„ break æ¥å£
            cpp_break_success = False
            if CPP_SERVER_URL:
                try:
                    break_resp = requests.post(
                        f"{CPP_SERVER_URL}/v1/stream/break",
                        json={"reason": "user_interrupt_from_health_thread"},
                        timeout=5.0
                    )
                    if break_resp.status_code == 200:
                        print(f"[ç‹¬ç«‹çº¿ç¨‹] C++ ç”Ÿæˆå·²ä¸­æ­¢: {break_resp.json()}", flush=True)
                        cpp_break_success = True
                    else:
                        print(f"[ç‹¬ç«‹çº¿ç¨‹] C++ break è°ƒç”¨å¤±è´¥: {break_resp.status_code}", flush=True)
                except Exception as e:
                    print(f"[ç‹¬ç«‹çº¿ç¨‹] C++ break è°ƒç”¨å¼‚å¸¸: {e}", flush=True)
            
            response = json.dumps({
                "success": True,
                "message": "å½“å‰è½®å¯¹è¯å·²æ‰“æ–­",
                "state": "break",
                "cpp_break": cpp_break_success
            })
            
            self.send_response(200)
            self.send_header("Content-Type", "application/json")
            self.send_header("Access-Control-Allow-Origin", "*")
            self.end_headers()
            self.wfile.write(response.encode())
            
        elif self.path == "/omni/stop":
            # å¿«é€Ÿåœæ­¢ - è®¾ç½® break æ ‡å¿—å¹¶è°ƒç”¨ C++ break æ¥å£
            print("======= [ç‹¬ç«‹çº¿ç¨‹] æ”¶åˆ°å¿«é€Ÿåœæ­¢æŒ‡ä»¤ =======", flush=True)
            
            # è®¾ç½® break æ ‡å¿—
            is_breaking = True
            print("[ç‹¬ç«‹çº¿ç¨‹] is_breaking å·²è®¾ç½®ä¸º True (stop)", flush=True)
            
            # è°ƒç”¨ C++ æœåŠ¡å™¨çš„ break æ¥å£
            cpp_break_success = False
            if CPP_SERVER_URL:
                try:
                    break_resp = requests.post(
                        f"{CPP_SERVER_URL}/v1/stream/break",
                        json={"reason": "session_stop_from_health_thread"},
                        timeout=5.0
                    )
                    if break_resp.status_code == 200:
                        print(f"[ç‹¬ç«‹çº¿ç¨‹] C++ ç”Ÿæˆå·²ä¸­æ­¢ (stop): {break_resp.json()}", flush=True)
                        cpp_break_success = True
                    else:
                        print(f"[ç‹¬ç«‹çº¿ç¨‹] C++ break è°ƒç”¨å¤±è´¥ (stop): {break_resp.status_code}", flush=True)
                except Exception as e:
                    print(f"[ç‹¬ç«‹çº¿ç¨‹] C++ break è°ƒç”¨å¼‚å¸¸ (stop): {e}", flush=True)
            
            response = json.dumps({
                "success": True,
                "message": "ä¼šè¯å·²åœæ­¢",
                "state": "session_stop",
                "cpp_break": cpp_break_success
            })
            
            self.send_response(200)
            self.send_header("Content-Type", "application/json")
            self.send_header("Access-Control-Allow-Origin", "*")
            self.end_headers()
            self.wfile.write(response.encode())
            
        else:
            self.send_response(404)
            self.end_headers()
    
    def do_OPTIONS(self):
        """å¤„ç†CORSé¢„æ£€è¯·æ±‚"""
        self.send_response(200)
        self.send_header("Access-Control-Allow-Origin", "*")
        self.send_header("Access-Control-Allow-Methods", "GET, POST, OPTIONS")
        self.send_header("Access-Control-Allow-Headers", "*")
        self.end_headers()


def start_health_server(port: int):
    """åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­å¯åŠ¨å¥åº·æ£€æŸ¥å’Œæ‰“æ–­æœåŠ¡å™¨
    
    è¯¥æœåŠ¡å™¨è¿è¡Œåœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­ï¼Œä¸å—ä¸»çº¿ç¨‹æ¨ç†ä»»åŠ¡é˜»å¡ã€‚
    æ”¯æŒå¿«é€Ÿå“åº”æ‰“æ–­è¯·æ±‚ï¼Œå³ä½¿æ¨¡å‹æ­£åœ¨ç”Ÿæˆä¸­ä¹Ÿèƒ½ç«‹å³å¤„ç†ã€‚
    
    æ”¯æŒçš„æ¥å£ï¼š
    - GET  /health     - å¥åº·æ£€æŸ¥
    - POST /omni/break - å¿«é€Ÿæ‰“æ–­ï¼ˆæ¨ç†æœŸé—´å¯ç”¨ï¼‰
    - POST /omni/stop  - å¿«é€Ÿåœæ­¢ï¼ˆæ¨ç†æœŸé—´å¯ç”¨ï¼‰
    """
    health_port = port + 1
    server = HTTPServer(("0.0.0.0", health_port), HealthCheckHandler)
    print(f"ç‹¬ç«‹å¥åº·æ£€æŸ¥/æ‰“æ–­æœåŠ¡å™¨å·²å¯åŠ¨: http://0.0.0.0:{health_port}", flush=True)
    print(f"  - GET  /health     - å¥åº·æ£€æŸ¥", flush=True)
    print(f"  - POST /omni/break - å¿«é€Ÿæ‰“æ–­", flush=True)
    print(f"  - POST /omni/stop  - å¿«é€Ÿåœæ­¢", flush=True)
    server.serve_forever()


def get_local_ip():
    """è·å–æœ¬æœº IP åœ°å€"""
    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    try:
        # è¿æ¥åˆ°ä¸€ä¸ªä¸ä¼šçœŸçš„é€šä¿¡çš„å…¬ç½‘åœ°å€
        s.connect(('8.8.8.8', 80))
        ip = s.getsockname()[0]
    finally:
        s.close()
    return ip


def register_service_node(port: int, duplex_mode: bool):
    """æ³¨å†ŒæœåŠ¡èŠ‚ç‚¹åˆ°è°ƒåº¦ä¸­å¿ƒï¼ˆå¦‚æœé…ç½®äº† REGISTER_URLï¼‰"""
    if not REGISTER_URL:
        print("è·³è¿‡æœåŠ¡æ³¨å†Œï¼ˆæœªé…ç½® REGISTER_URLï¼‰", flush=True)
        return
    
    try:
        url = f"{REGISTER_URL}/api/inference/register"
        local_ip = get_local_ip()
        # æ ¹æ® duplex_mode è®¾ç½® model_type
        model_type = "duplex" if duplex_mode else "simplex"
        data = {
            "ip": local_ip,
            "port": port,
            "model_port": port,
            "model_type": model_type,
            "session_type": "release",  # æ ‡è®°ä¸º C++ åç«¯
            "service_name": "o45-cpp",
        }
        print(f"æ­£åœ¨æ³¨å†ŒæœåŠ¡èŠ‚ç‚¹: url={url}, data={data}", flush=True)
        response = requests.post(url, json=data, timeout=10)
        if response.status_code == 200:
            print(f"æœåŠ¡èŠ‚ç‚¹æ³¨å†ŒæˆåŠŸ: {response.text}", flush=True)
        else:
            print(f"æœåŠ¡èŠ‚ç‚¹æ³¨å†Œå¤±è´¥: HTTP {response.status_code}, å“åº”: {response.text}", flush=True)
    except Exception as e:
        import traceback
        print(f"æœåŠ¡èŠ‚ç‚¹æ³¨å†Œå¼‚å¸¸: {e}", flush=True)
        traceback.print_exc()


def reset_output_dir():
    """å¯åŠ¨æ—¶é‡ç½® output ç›®å½•ï¼ˆrm -rf + mkdirï¼‰"""
    if os.path.exists(CPP_OUTPUT_DIR):
        try:
            shutil.rmtree(CPP_OUTPUT_DIR)
            print(f"[å¯åŠ¨æ¸…ç†] å·²åˆ é™¤ output ç›®å½•: {CPP_OUTPUT_DIR}", flush=True)
        except Exception as e:
            print(f"[å¯åŠ¨æ¸…ç†] åˆ é™¤ output ç›®å½•å¤±è´¥: {e}", flush=True)
    
    try:
        os.makedirs(CPP_OUTPUT_DIR, exist_ok=True)
        print(f"[å¯åŠ¨æ¸…ç†] å·²åˆ›å»º output ç›®å½•: {CPP_OUTPUT_DIR}", flush=True)
    except Exception as e:
        print(f"[å¯åŠ¨æ¸…ç†] åˆ›å»º output ç›®å½•å¤±è´¥: {e}", flush=True)


def clear_output_subfolders():
    """æ¸…ç©º output ç›®å½•ä¸‹æ¯ä¸ªå­æ–‡ä»¶å¤¹çš„å†…å®¹ï¼Œä½†ä¿ç•™ä¸€çº§å­æ–‡ä»¶å¤¹æœ¬èº«"""
    if not os.path.exists(CPP_OUTPUT_DIR):
        print(f"[æ¸…ç©ºè¾“å‡º] output ç›®å½•ä¸å­˜åœ¨: {CPP_OUTPUT_DIR}", flush=True)
        return
    
    cleared_count = 0
    for item in os.listdir(CPP_OUTPUT_DIR):
        item_path = os.path.join(CPP_OUTPUT_DIR, item)
        if os.path.isdir(item_path):
            # æ¸…ç©ºå­æ–‡ä»¶å¤¹å†…å®¹
            for sub_item in os.listdir(item_path):
                sub_item_path = os.path.join(item_path, sub_item)
                try:
                    if os.path.isdir(sub_item_path):
                        shutil.rmtree(sub_item_path)
                    else:
                        os.remove(sub_item_path)
                    cleared_count += 1
                except Exception as e:
                    print(f"[æ¸…ç©ºè¾“å‡º] åˆ é™¤å¤±è´¥ {sub_item_path}: {e}", flush=True)
    
    print(f"[æ¸…ç©ºè¾“å‡º] å·²æ¸…ç©º {CPP_OUTPUT_DIR} ä¸‹çš„å­æ–‡ä»¶å¤¹å†…å®¹ (åˆ é™¤ {cleared_count} é¡¹)", flush=True)


def start_cpp_server(model_dir: str, gpu_devices: str, port: int):
    """å¯åŠ¨ C++ llama-server"""
    global cpp_server_process
    
    # æ„å»ºå¯åŠ¨å‘½ä»¤
    llamacpp_root = LLAMACPP_ROOT
    
    # æŸ¥æ‰¾ llama-server å¯æ‰§è¡Œæ–‡ä»¶
    # ä¼˜å…ˆä½¿ç”¨ build/binï¼Œå›é€€åˆ° preset ç›®å½•
    import platform
    server_bin = None
    candidates = [
        os.path.join(llamacpp_root, "build/bin/llama-server"),              # Linux/macOS default
        os.path.join(llamacpp_root, "build/bin/Release/llama-server.exe"),  # Windows MSVC
        os.path.join(llamacpp_root, "build/bin/llama-server.exe"),          # Windows other
    ]
    if platform.system() == "Darwin":
        candidates.append(os.path.join(llamacpp_root, "build-arm64-apple-clang-release/bin/llama-server"))
    elif platform.system() != "Windows":
        candidates.append(os.path.join(llamacpp_root, "build-x64-linux-cuda-release/bin/llama-server"))
    for c in candidates:
        if os.path.exists(c):
            server_bin = c
            break
    if server_bin is None:
        server_bin = candidates[0]  # fallback for error message
    
    # model_dir å¯ä»¥æ˜¯ç»å¯¹è·¯å¾„æˆ–ç›¸å¯¹è·¯å¾„
    if os.path.isabs(model_dir):
        model_path = os.path.join(model_dir, DEFAULT_LLM_MODEL)
    else:
        model_path = os.path.join(llamacpp_root, model_dir, DEFAULT_LLM_MODEL)
    
    if not os.path.exists(server_bin):
        raise RuntimeError(f"C++ server binary not found: {server_bin}")
    
    if not os.path.exists(model_path):
        raise RuntimeError(f"Model not found: {model_path}")
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    env = os.environ.copy()
    
    # ğŸ”§ [è·¨å¹³å°] æ ¹æ®ç³»ç»Ÿè®¾ç½®ä¸åŒçš„ç¯å¢ƒå˜é‡
    if platform.system() == "Darwin":  # macOS
        # macOS ä½¿ç”¨ Metalï¼Œä¸éœ€è¦ CUDA ç¯å¢ƒå˜é‡
        # è®¾ç½® DYLD_LIBRARY_PATH ä»¥æ‰¾åˆ°åŠ¨æ€åº“
        dyld_paths = [
            os.path.dirname(server_bin),  # ä½¿ç”¨å®é™…çš„ server_bin ç›®å½•
            env.get('DYLD_LIBRARY_PATH', '')
        ]
        env["DYLD_LIBRARY_PATH"] = ":".join(p for p in dyld_paths if p)
        print(f"Platform: macOS (Metal)", flush=True)
        print(f"DYLD_LIBRARY_PATH={env.get('DYLD_LIBRARY_PATH', '')[:200]}", flush=True)
    else:  # Linux with CUDA
        env["CUDA_VISIBLE_DEVICES"] = gpu_devices
        # ä½¿ç”¨ CUDA åº“è·¯å¾„
        cuda_env_path = os.environ.get("CUDA_LIB_PATH", "/usr/local/cuda/lib64")
        cuda_lib_paths = [
            cuda_env_path,
            llamacpp_root + "/build/bin",  # libggml-cuda.so, libomni.so ç­‰
            "/usr/lib/x86_64-linux-gnu",
            env.get('LD_LIBRARY_PATH', '')
        ]
        env["LD_LIBRARY_PATH"] = ":".join(p for p in cuda_lib_paths if p)
        print(f"Platform: Linux (CUDA)", flush=True)
        print(f"CUDA_VISIBLE_DEVICES={gpu_devices}", flush=True)
        print(f"LD_LIBRARY_PATH={env['LD_LIBRARY_PATH'][:300]}", flush=True)
    
    # å¯åŠ¨æ—¶æŒ‡å®š --modelï¼Œomni_init ä¼šå¤ç”¨å·²åŠ è½½çš„æ¨¡å‹
    cmd = [
        server_bin,
        "--host", "0.0.0.0",
        "--port", str(port),
        "--model", model_path,
        "--ctx-size", str(DEFAULT_CTX_SIZE),
        "--n-gpu-layers", str(DEFAULT_N_GPU_LAYERS),
        "--repeat-penalty", "1.05",
        "--temp", "0.7",
    ]
    
    print(f"å¯åŠ¨ C++ llama-server: {' '.join(cmd)}", flush=True)
    
    # å¯åŠ¨è¿›ç¨‹
    cpp_server_process = subprocess.Popen(
        cmd,
        env=env,
        cwd=llamacpp_root,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        bufsize=1,
        encoding='utf-8',
        errors='replace'
    )
    
    # å¯åŠ¨æ—¥å¿—è¯»å–çº¿ç¨‹
    def log_reader():
        try:
            for line in cpp_server_process.stdout:
                print(f"[CPP] {line.rstrip()}", flush=True)
        except Exception as e:
            print(f"[CPP log_reader] å¼‚å¸¸: {e}", flush=True)
    
    log_thread = threading.Thread(target=log_reader, daemon=True)
    log_thread.start()
    
    # ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨
    max_wait = 180
    for i in range(max_wait):
        try:
            resp = requests.get(f"http://{CPP_SERVER_HOST}:{port}/health", timeout=2)
            if resp.status_code == 200:
                print(f"C++ llama-server å¯åŠ¨æˆåŠŸ (ç­‰å¾… {i+1} ç§’)", flush=True)
                return True
        except:
            pass
        time.sleep(1)
    
    raise RuntimeError(f"C++ llama-server å¯åŠ¨è¶…æ—¶ ({max_wait}ç§’)")


def stop_cpp_server():
    """åœæ­¢ C++ llama-server"""
    global cpp_server_process
    if cpp_server_process:
        print("åœæ­¢ C++ llama-server...", flush=True)
        cpp_server_process.terminate()
        try:
            cpp_server_process.wait(timeout=5)
        except subprocess.TimeoutExpired:
            cpp_server_process.kill()
        cpp_server_process = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    global http_client, health_server_thread, CPP_SERVER_PORT, CPP_SERVER_URL
    
    # åŠ¨æ€è®¡ç®— C++ ç«¯å£ï¼šPython ç«¯å£ + 10000
    CPP_SERVER_PORT = app.state.port + 10000
    CPP_SERVER_URL = f"http://{CPP_SERVER_HOST}:{CPP_SERVER_PORT}"
    print(f"C++ æœåŠ¡å™¨ç«¯å£: {CPP_SERVER_PORT} (Python ç«¯å£ {app.state.port} + 10000)", flush=True)
    print(f"æ˜¾å­˜ç›‘æ§: {'å¯ç”¨' if GPU_CHECK_ENABLED else 'ç¦ç”¨'} (è®¾ç½® GPU_MEMORY_CHECK=1 å¯ç”¨)", flush=True)
    
    # å¯åŠ¨å¥åº·æ£€æŸ¥æœåŠ¡å™¨
    health_server_thread = threading.Thread(
        target=start_health_server,
        args=(app.state.port,),
        daemon=True
    )
    health_server_thread.start()
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•ï¼ˆå¯åŠ¨æ—¶å…ˆæ¸…ç©ºæ—§æ•°æ®å†åˆ›å»ºï¼‰
    import shutil
    if os.path.exists(TEMP_DIR):
        shutil.rmtree(TEMP_DIR, ignore_errors=True)
    os.makedirs(TEMP_DIR, exist_ok=True)
    
    # å¯åŠ¨æ—¶æ¸…ç† output ç›®å½•
    reset_output_dir()
    
    # å¯åŠ¨ C++ æœåŠ¡å™¨
    print("æ­£åœ¨å¯åŠ¨ C++ llama-server...", flush=True)
    try:
        start_cpp_server(
            model_dir=app.state.model_dir,
            gpu_devices=app.state.gpu_devices,
            port=CPP_SERVER_PORT
        )
    except Exception as e:
        print(f"C++ æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {e}", flush=True)
        raise
    
    # åˆ›å»º HTTP å®¢æˆ·ç«¯
    http_client = httpx.AsyncClient(timeout=httpx.Timeout(300.0, connect=10.0))
    
    # ğŸ”§ [é¢„åˆå§‹åŒ–] Server å¯åŠ¨æ—¶å°±åˆå§‹åŒ–æ‰€æœ‰æ¨¡å—ï¼ˆLLM+TTS+APM+Python T2Wï¼‰
    # è¿™æ ·ç”¨æˆ·è°ƒç”¨ /omni/init_sys_prompt æ—¶å°±ä¸éœ€è¦ç­‰å¾… ~12s äº†
    print("æ­£åœ¨é¢„åˆå§‹åŒ– omni contextï¼ˆTTS + APM + Python T2Wï¼‰...", flush=True)
    try:
        model_dir = app.state.model_dir
        # TTS æ¨¡å‹åœ¨ tts/ ç›®å½•
        tts_bin_dir = os.path.join(model_dir, "tts")
        
        pre_init_request = {
            "media_type": 2,  # ğŸ”§ [ä¿®å¤] ä½¿ç”¨ omni æ¨¡å¼é¢„åˆå§‹åŒ–ï¼Œè¿™æ · VPM ä¹Ÿä¼šè¢«åŠ è½½
            "use_tts": True,
            "duplex_mode": app.state.default_duplex_mode,
            "model_dir": model_dir,
            "tts_bin_dir": tts_bin_dir,
            "tts_gpu_layers": 100,
            "token2wav_device": TOKEN2WAV_DEVICE,
            "output_dir": CPP_OUTPUT_DIR,
        }
        
        # è§†è§‰ç¼–ç å™¨åç«¯
        pre_init_request["vision_backend"] = VISION_BACKEND
        
        # ä½¿ç”¨å›ºå®šéŸ³è‰²æ–‡ä»¶è¿›è¡Œé¢„åˆå§‹åŒ–
        if os.path.exists(FIXED_TIMBRE_PATH):
            pre_init_request["voice_audio"] = FIXED_TIMBRE_PATH
        
        pre_init_resp = await http_client.post(
            f"{CPP_SERVER_URL}/v1/stream/omni_init",
            json=pre_init_request,
            timeout=120.0  # é¢„åˆå§‹åŒ–å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´
        )
        
        if pre_init_resp.status_code == 200:
            global model_state_initialized, current_duplex_mode, current_msg_type
            model_state_initialized = True
            current_duplex_mode = app.state.default_duplex_mode
            current_msg_type = 2  # ğŸ”§ [ä¿®å¤] omni æ¨¡å¼ï¼Œæ”¯æŒ audio å’Œè§†é¢‘
            print(f"é¢„åˆå§‹åŒ–æˆåŠŸ: {pre_init_resp.json()}", flush=True)
        else:
            print(f"é¢„åˆå§‹åŒ–å¤±è´¥ï¼ˆä¸å½±å“åç»­ä½¿ç”¨ï¼‰: {pre_init_resp.text}", flush=True)
    except Exception as e:
        print(f"é¢„åˆå§‹åŒ–å¼‚å¸¸ï¼ˆä¸å½±å“åç»­ä½¿ç”¨ï¼‰: {e}", flush=True)
    
    print("MiniCPMO C++ HTTP æœåŠ¡å™¨åˆå§‹åŒ–å®Œæˆ", flush=True)
    
    # æ³¨å†ŒæœåŠ¡èŠ‚ç‚¹ï¼ˆä½¿ç”¨é»˜è®¤æ¨¡å¼ï¼‰
    try:
        register_service_node(port=app.state.port, duplex_mode=app.state.default_duplex_mode)
    except Exception as e:
        print(f"æœåŠ¡èŠ‚ç‚¹æ³¨å†Œå¤±è´¥: {e}", flush=True)
    
    try:
        yield
    finally:
        # å…³é—­ HTTP å®¢æˆ·ç«¯
        if http_client:
            await http_client.aclose()
        # åœæ­¢ C++ æœåŠ¡å™¨
        stop_cpp_server()


app = FastAPI(title="MiniCPMO C++ HTTP Server (Unified)", lifespan=lifespan)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ====================== è¯·æ±‚æ¨¡å‹ ======================
class InitSysPromptRequest(BaseModel):
    media_type: Optional[str] = None  # "audio" æˆ– "omni"
    duplex_mode: Optional[bool] = None  # æ˜¯å¦å¯ç”¨åŒå·¥æ¨¡å¼ï¼ˆNone è¡¨ç¤ºä½¿ç”¨é»˜è®¤å€¼ï¼‰
    high_quality_mode: Optional[bool] = False  # ğŸ”§ [é«˜æ¸…æ¨¡å¼] å¯ç”¨å›¾ç‰‡åˆ‡ç‰‡ (max_slice_nums=2)
    high_fps_mode: Optional[bool] = False  # ğŸ”§ [é«˜åˆ·æ¨¡å¼] 1ç§’5å¸§ stack
    language: Optional[str] = "zh"  # ğŸ”§ [è¯­è¨€åˆ‡æ¢] "zh" ä¸­æ–‡, "en" è‹±æ–‡

class StreamingPrefillRequest(BaseModel):
    audio: Optional[str] = None  # base64ç¼–ç çš„éŸ³é¢‘
    image: Optional[str] = None  # base64ç¼–ç çš„å›¾ç‰‡
    # ğŸ”§ [é«˜åˆ·æ¨¡å¼] å›¾ç‰‡æŒ‰ image_audio_id åˆ†ç»„
    image_audio_id: Optional[int] = None  # å›¾ç‰‡éŸ³é¢‘å…³è”IDï¼ˆç”¨äºæ ‡è®°åŒä¸€ç»„éŸ³é¢‘å’Œå›¾ç‰‡ï¼‰
    frame_index: Optional[int] = None  # å½“å‰å¸§ç´¢å¼• (0=ä¸»å›¾, 1-4=å­å›¾ç”¨äºstack)
    max_slice_nums: Optional[int] = None
    session_id: Optional[str] = None
    is_last_chunk: bool = False


# ====================== API ç«¯ç‚¹ ======================
@app.get("/health")
async def health():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "message": "æœåŠ¡æ­£å¸¸ (C++ backend)",
        "backend": "cpp",
        "duplex_mode": current_duplex_mode
    }


@app.post("/omni/stop")
async def omni_stop(session_id: Optional[str] = None):
    """ä¼šè¯åœæ­¢ï¼ˆä¸­æ­¢å½“å‰ç”Ÿæˆï¼Œä½†ä¿ç•™ KV cache å’Œä¼šè¯çŠ¶æ€ï¼‰"""
    global current_active_session_id, current_request_counter, current_round_number
    global model_state_initialized, pending_prefill_data, is_breaking
    global wav_timing_log_file, last_wav_send_time
    global global_sent_wav_count, global_parsed_line_count, global_parsed_texts, global_text_send_idx, global_sent_wav_files
    
    print("======= æ”¶åˆ°ä¼šè¯åœæ­¢æŒ‡ä»¤ =======", flush=True)
    
    stopped_session_id = current_active_session_id
    
    # è°ƒç”¨ C++ æœåŠ¡å™¨çš„ break æ¥å£ï¼Œä¸­æ­¢ç”Ÿæˆä½†ä¸æ¸…ç©º KV cache
    try:
        break_resp = await http_client.post(
            f"{CPP_SERVER_URL}/v1/stream/break",
            json={}
        )
        if break_resp.status_code == 200:
            print(f"[omni_stop] C++ ç”Ÿæˆå·²ä¸­æ­¢: {break_resp.json()}", flush=True)
        else:
            print(f"[omni_stop] C++ break è°ƒç”¨å¤±è´¥: {break_resp.status_code} - {break_resp.text}", flush=True)
    except Exception as e:
        print(f"[omni_stop] C++ break è°ƒç”¨å¼‚å¸¸: {e}", flush=True)
    
    # è®¾ç½® break æ ‡å¿—ï¼Œè®© generate_stream åœæ­¢å‘é€æ•°æ®
    is_breaking = True
    
    # å…³é—­å¹¶å†™å…¥ WAV æ—¶åºæ—¥å¿—æ€»ç»“
    if wav_timing_log_file:
        try:
            wav_timing_log_file.write(f"{'-'*120}\n")
            wav_timing_log_file.write(f"[ä¼šè¯åœæ­¢] {datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')}\n")
            wav_timing_log_file.close()
            print(f"[ğŸ“Š WAV æ—¶åºæ—¥å¿—å·²å†™å…¥] {WAV_TIMING_LOG_PATH}", flush=True)
        except:
            pass
        wav_timing_log_file = None
    last_wav_send_time = None
    
    # é‡ç½®è®¡æ•°å™¨å’Œç¼“å­˜
    with session_lock:
        current_active_session_id = None
        current_request_counter = 0
        current_round_number = 0
        pending_prefill_data = None
        # åŒå·¥æ¨¡å¼éœ€è¦é‡ç½®çš„å…¨å±€çŠ¶æ€
        global_sent_wav_count = 0
        global_parsed_line_count = 0
        global_parsed_texts = []
        global_text_send_idx = 0
        global_sent_wav_files = set()
    
    print(f"ä¼šè¯å·²æš‚åœ: {stopped_session_id} (ä¼šè¯çŠ¶æ€ä¿ç•™ï¼Œå¯ç»§ç»­å¯¹è¯)", flush=True)
    print("======= ç”Ÿæˆå·²ä¸­æ­¢ï¼Œä¼šè¯å’Œ KV cache ä¿ç•™ï¼Œå¯ç›´æ¥ç»§ç»­ prefill =======", flush=True)
    
    return {
        "success": True,
        "message": "ç”Ÿæˆå·²ä¸­æ­¢ï¼Œä¼šè¯ä¿ç•™ï¼Œå¯ç›´æ¥ç»§ç»­å¯¹è¯",
        "state": "generation_stopped",
        "session_id": stopped_session_id,
        "kv_cache_preserved": True
    }


@app.post("/omni/break")
async def omni_break():
    """å•è½®æ‰“æ–­ï¼ˆåªæ‰“æ–­å½“å‰è½®decodeï¼Œä¸é‡ç½®ä¼šè¯ï¼‰"""
    global is_breaking
    
    if not model_state_initialized:
        raise HTTPException(status_code=503, detail="æ¨¡å‹æœªåˆå§‹åŒ–")
    
    try:
        print("======= æ”¶åˆ°å•è½®æ‰“æ–­æŒ‡ä»¤ =======", flush=True)
        
        # ã€å…³é”®ã€‘ç«‹å³è®¾ç½® break æ ‡å¿—ï¼Œè®© generate_stream åœæ­¢å‘å‰ç«¯å‘é€æ•°æ®
        is_breaking = True
        print("[omni_break] is_breaking å·²è®¾ç½®ä¸º Trueï¼Œä¸­é—´å±‚å°†åœæ­¢å‘é€æ•°æ®", flush=True)
        
        # è°ƒç”¨ C++ æœåŠ¡å™¨çš„ break æ¥å£ï¼Œä¸­æ­¢å½“å‰ç”Ÿæˆ
        try:
            break_resp = await http_client.post(
                f"{CPP_SERVER_URL}/v1/stream/break",
                json={}
            )
            if break_resp.status_code == 200:
                print(f"[omni_break] C++ ç”Ÿæˆå·²ä¸­æ­¢: {break_resp.json()}", flush=True)
            else:
                print(f"[omni_break] C++ break è°ƒç”¨å¤±è´¥: {break_resp.status_code} - {break_resp.text}", flush=True)
        except Exception as e:
            print(f"[omni_break] C++ break è°ƒç”¨å¼‚å¸¸: {e}", flush=True)
        
        print("======= å½“å‰è½®å¯¹è¯å·²æ‰“æ–­ï¼ˆä¼šè¯çŠ¶æ€ä¿ç•™ï¼‰=======", flush=True)
        return {"success": True, "message": "å½“å‰è½®å¯¹è¯å·²æ‰“æ–­", "state": "break"}
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"æ‰“æ–­å¤±è´¥: {str(e)}")


@app.post("/omni/init_sys_prompt")
async def init_sys_prompt(request: InitSysPromptRequest):
    """åˆå§‹åŒ–ç³»ç»Ÿæç¤º
    
    C++ ç‰ˆæœ¬ï¼šserver å¯åŠ¨æ—¶å·²åŠ è½½æ‰€æœ‰æ¨¡å‹ï¼Œæ­¤æ¥å£åªåšçŠ¶æ€åˆå§‹åŒ–
    - é¦–æ¬¡è°ƒç”¨ï¼šåˆå§‹åŒ– omni ä¸Šä¸‹æ–‡ï¼ˆåŠ è½½ TTS/APM/VPM ç­‰æ¨¡å—ï¼Œå¤ç”¨å·²æœ‰ LLMï¼‰
    - åç»­è°ƒç”¨ï¼šå¿«é€Ÿæ¢å¤ä¼šè¯çŠ¶æ€
    
    æ”¯æŒæ¨¡å¼åˆ‡æ¢ï¼š
    - duplex_mode=True: åŒå·¥æ¨¡å¼ï¼Œç›´æ¥è½¬å‘ prefillï¼Œå…¨å±€ WAV è®¡æ•°å™¨
    - duplex_mode=False: å•å·¥æ¨¡å¼ï¼Œä½¿ç”¨"å»¶è¿Ÿä¸€æ‹"æœºåˆ¶
    """
    global current_msg_type, current_duplex_mode, current_active_session_id, current_request_counter
    global current_round_number, model_state_initialized, pending_prefill_data
    global current_high_quality_mode, current_high_fps_mode
    global global_sent_wav_count, global_parsed_line_count, global_parsed_texts, global_text_send_idx, global_sent_wav_files
    global wav_timing_log_file, last_wav_send_time
    global is_breaking
    
    # ğŸ”§ [ä¿®å¤] é‡ç½® is_breaking æ ‡å¿—ï¼Œé˜²æ­¢ä¸Šä¸€æ¬¡ stop åæ®‹ç•™çš„çŠ¶æ€å½±å“æ–°ä¼šè¯
    # åœºæ™¯ï¼šè°ƒåº¦ä¸­å¿ƒè°ƒç”¨ /omni/stop è®¾ç½® is_breaking=Trueï¼Œä¹‹åæ–°ç”¨æˆ·å¼€å§‹ä¼šè¯
    #       å¦‚æœä¸åœ¨ init_sys_prompt ä¸­é‡ç½®ï¼Œæ–°ç”¨æˆ·çš„ streaming_generate ä¼šæ£€æµ‹åˆ°æ®‹ç•™çš„ is_breaking=True
    if is_breaking:
        print("[init_sys_prompt] æ£€æµ‹åˆ°æ®‹ç•™çš„ is_breaking=Trueï¼Œé‡ç½®ä¸º False", flush=True)
        is_breaking = False
    
    # ğŸ”§ [ä¿®å¤] æ£€æŸ¥æ˜¯å¦æ­£åœ¨é‡å¯ï¼Œé˜²æ­¢é‡å¯æœŸé—´çš„è¯·æ±‚å¯¼è‡´å†²çª
    if cpp_restarting:
        print("[init_sys_prompt] æœåŠ¡æ­£åœ¨é‡å¯ä¸­ï¼Œè¯·ç¨åé‡è¯•", flush=True)
        raise HTTPException(status_code=503, detail="æœåŠ¡æ­£åœ¨é‡å¯ä¸­ï¼Œè¯·ç¨åé‡è¯•")
    
    try:
        # æ¸…ç©º output å­ç›®å½•ï¼ˆæ¯æ¬¡ init æ—¶æ¸…ç©ºä¸Šä¸€æ¬¡çš„è¾“å‡ºï¼‰
        clear_output_subfolders()
        
        # è®¾ç½® duplex_modeï¼ˆä¼˜å…ˆä½¿ç”¨è¯·æ±‚å‚æ•°ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤å€¼ï¼‰
        if request.duplex_mode is not None:
            duplex_mode = request.duplex_mode
        else:
            duplex_mode = app.state.default_duplex_mode
        
        # ğŸ”§ [ä¿®å¤] ä¸åœ¨ init_sys_prompt æ—¶è°ƒç”¨ reset æ¸…ç©º KV cache
        # åŸå› ï¼šé¢„åˆå§‹åŒ–æ—¶å·²ç» prefill äº† system promptï¼Œæ¸…ç©º KV cache ä¼šå¯¼è‡´ä¸Šä¸‹æ–‡ä¸¢å¤±
        # LLM çº¿ç¨‹åœ¨ decode æ—¶ä¼šè‡ªå·±æ¸…ç†ç”¨æˆ·å¯¹è¯éƒ¨åˆ†ï¼ˆä¿ç•™ n_keep = system promptï¼‰
        
        # ç”Ÿæˆæ–°çš„ä¼šè¯ID
        new_session_id = str(uuid.uuid4())[:8]
        
        # è®¾ç½® msg_type
        if request.media_type:
            if request.media_type.lower() == "audio":
                msg_type = 1
            elif request.media_type.lower() in ["video", "omni"]:
                msg_type = 2
            else:
                raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„media_type: {request.media_type}")
        else:
            msg_type = 2  # é»˜è®¤ omni æ¨¡å¼
        
        # ğŸ”§ [é«˜æ¸…æ¨¡å¼] è®¾ç½® max_slice_nums
        high_quality_mode = request.high_quality_mode if request.high_quality_mode is not None else False
        
        # ğŸ”§ [é«˜åˆ·æ¨¡å¼] è®¾ç½® 1ç§’5å¸§ stack
        high_fps_mode = request.high_fps_mode if request.high_fps_mode is not None else False
        
        # ğŸ”§ [è¯­è¨€åˆ‡æ¢] è®¾ç½®è¯­è¨€ ("zh" æˆ– "en")
        language = request.language if request.language is not None else "zh"
        
        is_audio_mode = (msg_type == 1)
        mode_name = "audio" if is_audio_mode else "omni"
        duplex_name = "åŒå·¥" if duplex_mode else "å•å·¥"
        quality_name = "é«˜æ¸…" if high_quality_mode else "æ™®é€š"
        fps_name = "é«˜åˆ·" if high_fps_mode else "æ ‡å‡†å¸§ç‡"
        
        # æ£€æµ‹ duplex_mode æ˜¯å¦å˜åŒ–ï¼ˆç”¨äºè­¦å‘Šæ—¥å¿—ï¼‰
        # æ³¨æ„ï¼šæ¯ä¸ª server å®ä¾‹çš„ duplex_mode åœ¨å¯åŠ¨æ—¶ç¡®å®šï¼Œè¿è¡Œæ—¶ä¸åº”æ”¹å˜
        duplex_mode_changed = model_state_initialized and (current_duplex_mode != duplex_mode)
        if duplex_mode_changed:
            print(f"[è­¦å‘Š] duplex_mode ä» {current_duplex_mode} å˜ä¸º {duplex_mode}ï¼Œä½† server å·²åˆå§‹åŒ–ï¼Œæ­¤æ¬¡è¯·æ±‚çš„ duplex_mode å°†è¢«å¿½ç•¥", flush=True)
            duplex_mode = current_duplex_mode  # ä¿æŒåŸæœ‰æ¨¡å¼
        
        # ğŸ”§ [ä¿®å¤] æ£€æµ‹ media_type æ˜¯å¦å˜åŒ–ï¼ˆaudio <-> omniï¼‰
        # ä¸åŒæ¨¡å¼éœ€è¦ä¸åŒçš„ system prompt
        media_type_changed = model_state_initialized and (current_msg_type != msg_type)
        if media_type_changed:
            print(f"[æ¨¡å¼åˆ‡æ¢] media_type ä» {current_msg_type} å˜ä¸º {msg_type}ï¼Œè°ƒç”¨ update_session_config", flush=True)
        
        current_msg_type = msg_type
        current_duplex_mode = duplex_mode
        
        # ğŸ”§ [ä¼˜åŒ–] é¦–æ¬¡æ—¶è°ƒç”¨ omni_initï¼Œmedia_type å˜åŒ–æ—¶è°ƒç”¨ update_session_config
        if not model_state_initialized:
            # model_dir å¯ä»¥æ˜¯ç»å¯¹è·¯å¾„æˆ–ç›¸å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äº llamacpp æ ¹ç›®å½•ï¼‰
            model_dir = app.state.model_dir
            # TTS æ¨¡å‹åœ¨ tts/ ç›®å½•
            tts_bin_dir = os.path.join(model_dir, "tts")
            
            cpp_request = {
                "media_type": msg_type,      # 1=audio, 2=omni
                "use_tts": True,             # å¯ç”¨ TTS è¯­éŸ³åˆæˆ
                "duplex_mode": duplex_mode,  # åŒå·¥/å•å·¥æ¨¡å¼
                "model_dir": model_dir,
                "tts_bin_dir": tts_bin_dir,
                "tts_gpu_layers": 100,
                "token2wav_device": TOKEN2WAV_DEVICE,
                "output_dir": CPP_OUTPUT_DIR,  # ğŸ”§ [å¤šå®ä¾‹æ”¯æŒ] ä¼ é€’é…ç½®çš„è¾“å‡ºç›®å½•
                "language": language,        # ğŸ”§ [è¯­è¨€åˆ‡æ¢] "zh" æˆ– "en"
            }
            
            # è§†è§‰ç¼–ç å™¨åç«¯
            cpp_request["vision_backend"] = VISION_BACKEND
            
            # ğŸ”§ [é«˜æ¸…æ¨¡å¼] è®¾ç½® max_slice_nums
            if high_quality_mode:
                cpp_request["max_slice_nums"] = 2  # é«˜æ¸…æ¨¡å¼ï¼šåˆ‡å›¾
                print(f"[é«˜æ¸…æ¨¡å¼] å¯ç”¨å›¾ç‰‡åˆ‡ç‰‡ max_slice_nums=2", flush=True)
            
            # ä¿å­˜æ¨¡å¼çŠ¶æ€
            current_high_quality_mode = high_quality_mode
            current_high_fps_mode = high_fps_mode
            
            print(f"[æ¨¡å¼è®¾ç½®] åŒå·¥={duplex_mode}, é«˜æ¸…={high_quality_mode}, é«˜åˆ·={high_fps_mode}", flush=True)
            
            # ä½¿ç”¨å›ºå®šéŸ³è‰²æ–‡ä»¶
            if os.path.exists(FIXED_TIMBRE_PATH):
                cpp_request["voice_audio"] = FIXED_TIMBRE_PATH
                print(f"ä½¿ç”¨éŸ³è‰²æ–‡ä»¶: {FIXED_TIMBRE_PATH}", flush=True)
            
            print(f"åˆå§‹åŒ–ï¼Œè°ƒç”¨ C++ omni_init: {json.dumps(cpp_request, ensure_ascii=False)}", flush=True)
            
            resp = await http_client.post(
                f"{CPP_SERVER_URL}/v1/stream/omni_init",
                json=cpp_request
            )
            
            if resp.status_code != 200:
                error_text = resp.text
                print(f"C++ omni_init å¤±è´¥: {error_text}", flush=True)
                raise HTTPException(status_code=500, detail=f"C++ omni_init å¤±è´¥: {error_text}")
            
            cpp_result = resp.json()
            print(f"C++ omni_init æˆåŠŸ: {cpp_result}", flush=True)
            model_state_initialized = True
            fast_resume = False
            init_message = f"åˆå§‹åŒ–å®Œæˆï¼ˆ{mode_name}æ¨¡å¼ï¼Œ{duplex_name}ï¼Œ{quality_name}ç”»è´¨ï¼Œ{fps_name}ï¼‰"
        elif media_type_changed:
            # ğŸ”§ [ä¼˜åŒ–] media_type å˜åŒ–ï¼Œè°ƒç”¨ update_session_configï¼ˆä¸é‡æ–°åŠ è½½æ¨¡å‹ï¼‰
            current_high_quality_mode = high_quality_mode
            current_high_fps_mode = high_fps_mode
            
            update_request = {
                "media_type": msg_type,
                "duplex_mode": duplex_mode,
                "language": language,  # ğŸ”§ [è¯­è¨€åˆ‡æ¢]
            }
            
            # ä½¿ç”¨å›ºå®šéŸ³è‰²æ–‡ä»¶é‡æ–° prefill system prompt
            if os.path.exists(FIXED_TIMBRE_PATH):
                update_request["voice_audio"] = FIXED_TIMBRE_PATH
            
            print(f"[æ¨¡å¼åˆ‡æ¢] è°ƒç”¨ C++ update_session_config: {json.dumps(update_request, ensure_ascii=False)}", flush=True)
            
            resp = await http_client.post(
                f"{CPP_SERVER_URL}/v1/stream/update_session_config",
                json=update_request,
                timeout=30.0
            )
            
            if resp.status_code != 200:
                error_text = resp.text
                print(f"C++ update_session_config å¤±è´¥: {error_text}", flush=True)
                raise HTTPException(status_code=500, detail=f"C++ update_session_config å¤±è´¥: {error_text}")
            
            cpp_result = resp.json()
            print(f"C++ update_session_config æˆåŠŸ: {cpp_result}", flush=True)
            fast_resume = False
            init_message = f"æ¨¡å¼åˆ‡æ¢å®Œæˆï¼ˆ{mode_name}æ¨¡å¼ï¼Œ{duplex_name}ï¼Œ{quality_name}ç”»è´¨ï¼Œ{fps_name}ï¼‰"
        else:
            # å·²åˆå§‹åŒ–ä¸”æ¨¡å¼æœªå˜ï¼Œä½†ä»éœ€é€šçŸ¥ C++ é‡ç½®çŠ¶æ€
            # ğŸ”§ [ä¿®å¤] è°ƒç”¨ update_session_config ç¡®ä¿ C++ ç«¯çŠ¶æ€æ­£ç¡®é‡ç½®
            # åŸå› ï¼šTTS çº¿ç¨‹å¯èƒ½è¿˜æœ‰æ®‹ç•™çŠ¶æ€ï¼Œéœ€è¦ç­‰å¾…å…¶å®Œæˆå¹¶æ¸…ç†é˜Ÿåˆ—
            current_high_quality_mode = high_quality_mode
            current_high_fps_mode = high_fps_mode
            
            update_request = {
                "media_type": msg_type,
                "duplex_mode": duplex_mode,
                "language": language,  # ğŸ”§ [è¯­è¨€åˆ‡æ¢]
            }
            
            # ä½¿ç”¨å›ºå®šéŸ³è‰²æ–‡ä»¶é‡æ–° prefill system prompt
            if os.path.exists(FIXED_TIMBRE_PATH):
                update_request["voice_audio"] = FIXED_TIMBRE_PATH
            
            print(f"[æé€Ÿæ¢å¤] è°ƒç”¨ C++ update_session_config é‡ç½®çŠ¶æ€: {json.dumps(update_request, ensure_ascii=False)}", flush=True)
            
            resp = await http_client.post(
                f"{CPP_SERVER_URL}/v1/stream/update_session_config",
                json=update_request,
                timeout=30.0
            )
            
            if resp.status_code != 200:
                error_text = resp.text
                print(f"[æé€Ÿæ¢å¤] C++ update_session_config å¤±è´¥: {error_text}", flush=True)
                raise HTTPException(status_code=500, detail=f"C++ update_session_config å¤±è´¥: {error_text}")
            
            cpp_result = resp.json()
            print(f"[æé€Ÿæ¢å¤] C++ update_session_config æˆåŠŸ: {cpp_result}", flush=True)
            fast_resume = True
            init_message = f"åˆå§‹åŒ–æˆåŠŸï¼ˆ{mode_name}æ¨¡å¼ï¼Œ{duplex_name}ï¼Œ{quality_name}ç”»è´¨ï¼Œ{fps_name}ï¼Œå¿«é€Ÿæ¢å¤ï¼‰"
        
        # å…³é—­ä¹‹å‰çš„æ—¥å¿—æ–‡ä»¶ï¼ˆå¦‚æœæœ‰ï¼‰
        if wav_timing_log_file:
            try:
                wav_timing_log_file.write(f"{'-'*120}\n")
                wav_timing_log_file.write(f"[æ–°ä¼šè¯åˆå§‹åŒ–ï¼Œå…³é—­æ—§æ—¥å¿—] {datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')}\n")
                wav_timing_log_file.close()
            except:
                pass
            wav_timing_log_file = None
        last_wav_send_time = None
        
        # æ›´æ–°ä¼šè¯çŠ¶æ€
        with session_lock:
            current_active_session_id = new_session_id
            current_request_counter = 0
            current_round_number = 0
            pending_prefill_data = None
            # åŒå·¥æ¨¡å¼éœ€è¦é‡ç½®çš„å…¨å±€çŠ¶æ€
            global_sent_wav_count = 0
            global_parsed_line_count = 0
            global_parsed_texts = []
            global_text_send_idx = 0
            global_sent_wav_files = set()
        
        # ğŸ”§ [é«˜åˆ·æ¨¡å¼] æ¸…ç†å›¾ç‰‡ç¼“å­˜
        with high_fps_cache_lock:
            high_fps_subimage_cache.clear()
            print(f"[init_sys_prompt] å·²æ¸…ç†é«˜åˆ·æ¨¡å¼å›¾ç‰‡ç¼“å­˜", flush=True)
        
        return {
            "success": True,
            "message": init_message,
            "msg_type": msg_type,
            "duplex_mode": duplex_mode,
            "session_id": new_session_id,
            "fast_resume": fast_resume
        }
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"åˆå§‹åŒ–å¤±è´¥: {str(e)}")


@app.post("/omni/streaming_prefill")
async def streaming_prefill(request: StreamingPrefillRequest):
    """æµå¼é¢„å¡«å……
    
    æ ¹æ® duplex_mode ä½¿ç”¨ä¸åŒçš„å¤„ç†é€»è¾‘ï¼š
    - å•å·¥æ¨¡å¼ï¼šä½¿ç”¨"å»¶è¿Ÿä¸€æ‹"æœºåˆ¶
    - åŒå·¥æ¨¡å¼ï¼šç›´æ¥è½¬å‘ç»™ C++ /v1/stream/prefill
    """
    global pending_prefill_data, current_request_counter
    
    # ğŸ”§ [ä¿®å¤] æ£€æŸ¥æ˜¯å¦æ­£åœ¨é‡å¯
    if cpp_restarting:
        raise HTTPException(status_code=503, detail="æœåŠ¡æ­£åœ¨é‡å¯ä¸­ï¼Œè¯·ç¨åé‡è¯•")
    
    if not current_active_session_id:
        raise HTTPException(
            status_code=400,
            detail="æœªæ‰¾åˆ°æ´»è·ƒä¼šè¯ï¼Œè¯·å…ˆè°ƒç”¨ /omni/init_sys_prompt åˆå§‹åŒ–ä¼šè¯"
        )
    
    prefill_start_time = time.time()
    
    # ========== æ€§èƒ½ç»Ÿè®¡å˜é‡ ==========
    timing_stats = {}
    
    try:
        # 1. è§£ç éŸ³é¢‘
        t0 = time.time()
        audio_np = None
        sr = 16000
        if request.audio:
            try:
                audio_bytes = base64.b64decode(request.audio)
                # å…ˆç”¨ soundfile è¯»å–ï¼Œè·å–åŸå§‹é‡‡æ ·ç‡
                audio_np, file_sr = sf.read(io.BytesIO(audio_bytes), dtype='float32')
                
                # å¦‚æœæ˜¯ç«‹ä½“å£°ï¼Œè½¬ä¸ºå•å£°é“
                if len(audio_np.shape) > 1:
                    audio_np = audio_np.mean(axis=1)
                
                # å¦‚æœé‡‡æ ·ç‡ä¸æ˜¯ 16kHzï¼Œä½¿ç”¨ librosa é‡é‡‡æ ·
                if file_sr != 16000:
                    audio_np = librosa.resample(audio_np, orig_sr=file_sr, target_sr=16000)
                
                audio_np = audio_np.astype(np.float32)
                sr = 16000
            except Exception as e:
                raise HTTPException(status_code=400, detail=f"éŸ³é¢‘æ•°æ®è§£ç å¤±è´¥: {str(e)}")
        timing_stats['audio_decode'] = (time.time() - t0) * 1000
        
        # 2. è§£ç å›¾ç‰‡
        t0 = time.time()
        pil_image = None
        if request.image:
            try:
                image_bytes = base64.b64decode(request.image)
                pil_image = Image.open(io.BytesIO(image_bytes))
                if pil_image.mode != 'RGB':
                    pil_image = pil_image.convert('RGB')
            except Exception as e:
                raise HTTPException(status_code=400, detail=f"å›¾ç‰‡æ•°æ®è§£ç å¤±è´¥: {str(e)}")
        timing_stats['image_decode'] = (time.time() - t0) * 1000
        
        # ğŸ”§ [é«˜åˆ·æ¨¡å¼] æ–°çš„å›¾ç‰‡/éŸ³é¢‘åˆ†ç¦»å¤„ç†é€»è¾‘
        # é€»è¾‘ï¼š
        # 1. ä¸»å›¾ï¼ˆframe_index=0ï¼‰ç«‹å³ prefill
        # 2. å­å›¾ï¼ˆframe_index=1-4ï¼‰ç¼“å­˜ï¼Œç­‰æ»¡4å¼ æˆ–æ”¶åˆ°éŸ³é¢‘æ—¶è§¦å‘
        # 3. éŸ³é¢‘åˆ°è¾¾æ—¶ï¼šå–å‡ºç¼“å­˜çš„å­å›¾ï¼Œstack å prefillï¼ˆå›¾ç‰‡åœ¨å‰ï¼‰
        
        # ğŸ”§ [é«˜æ¸…+é«˜åˆ·] æ ‡è®°æ˜¯å¦ä¸ºä¸»å›¾ï¼ˆç”¨äºå†³å®šé«˜æ¸…åˆ‡ç‰‡ï¼‰
        is_main_image = False
        
        if current_high_fps_mode and request.image_audio_id is not None:
            frame_idx = request.frame_index if request.frame_index is not None else 0
            
            # æƒ…å†µ1ï¼šåªæœ‰å›¾ç‰‡ï¼Œæ²¡æœ‰éŸ³é¢‘
            if pil_image is not None and audio_np is None:
                if frame_idx == 0:
                    # ä¸»å›¾ï¼šç«‹å³ prefillï¼Œä¸ç¼“å­˜
                    print(f"[é«˜åˆ·æ¨¡å¼] ä¸»å›¾åˆ°è¾¾ image_audio_id={request.image_audio_id}ï¼Œç«‹å³ prefill", flush=True)
                    pil_images = [pil_image]
                    audio_np = None  # æ˜ç¡®æ²¡æœ‰éŸ³é¢‘
                    is_main_image = True  # ğŸ”§ [é«˜æ¸…+é«˜åˆ·] æ ‡è®°ä¸ºä¸»å›¾
                    # ç»§ç»­åé¢çš„ prefill æµç¨‹
                else:
                    # å­å›¾ï¼ˆframe_index 1-4ï¼‰ï¼šç¼“å­˜
                    with high_fps_cache_lock:
                        if request.image_audio_id not in high_fps_subimage_cache:
                            high_fps_subimage_cache[request.image_audio_id] = {}
                        high_fps_subimage_cache[request.image_audio_id][frame_idx] = pil_image
                        cached_count = len(high_fps_subimage_cache[request.image_audio_id])
                        # æ£€æŸ¥æ˜¯å¦æ”¶é½4å¼ å­å›¾ï¼ˆframe 1,2,3,4ï¼‰
                        all_subframes_ready = all(
                            i in high_fps_subimage_cache[request.image_audio_id] 
                            for i in [1, 2, 3, 4]
                        )
                    
                    print(f"[é«˜åˆ·æ¨¡å¼] å­å›¾ç¼“å­˜ image_audio_id={request.image_audio_id}, frame={frame_idx}, å·²ç¼“å­˜{cached_count}å¸§", flush=True)
                    
                    if all_subframes_ready:
                        # æ”¶é½4å¼ å­å›¾ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å¾…å¤„ç†çš„éŸ³é¢‘
                        pending_audio = None
                        with high_fps_audio_lock:
                            if request.image_audio_id in high_fps_pending_audio:
                                pending_audio = high_fps_pending_audio.pop(request.image_audio_id)
                        
                        if pending_audio is not None:
                            # æœ‰å¾…å¤„ç†çš„éŸ³é¢‘ï¼Œå–å‡ºå­å›¾ï¼Œstackï¼Œç„¶å prefill
                            audio_np, sr, _ = pending_audio
                            with high_fps_cache_lock:
                                cached_frames = high_fps_subimage_cache.pop(request.image_audio_id, {})
                            sorted_frames = sorted(cached_frames.items(), key=lambda x: x[0])
                            subimages = [img for _, img in sorted_frames]
                            stacked_image = stack_images(subimages)
                            pil_images = [stacked_image]
                            print(f"[é«˜åˆ·æ¨¡å¼] å­å›¾æ”¶é½+å¾…å¤„ç†éŸ³é¢‘ï¼Œstack {len(subimages)} å¸§ï¼Œprefill", flush=True)
                            # ç»§ç»­åé¢çš„ prefill æµç¨‹
                        else:
                            # æ²¡æœ‰å¾…å¤„ç†çš„éŸ³é¢‘ï¼Œåªæ˜¯ç¼“å­˜å®Œæˆ
                            return {
                                "success": True,
                                "message": f"å­å›¾å·²ç¼“å­˜å®Œæ¯•ï¼Œç­‰å¾…éŸ³é¢‘ (image_audio_id={request.image_audio_id})",
                                "cached_frames": cached_count,
                                "mode": "high_fps_cache_ready"
                            }
                    else:
                        # è¿˜æ²¡æ”¶é½ï¼Œåªè¿”å›ç¼“å­˜çŠ¶æ€
                        return {
                            "success": True,
                            "message": f"å­å›¾å·²ç¼“å­˜ (image_audio_id={request.image_audio_id}, frame={frame_idx})",
                            "cached_frames": cached_count,
                            "mode": "high_fps_cache"
                        }
            
            # æƒ…å†µ2ï¼šæœ‰éŸ³é¢‘ï¼ˆå¯èƒ½åŒæ—¶æœ‰å›¾ç‰‡ï¼‰
            elif audio_np is not None:
                # ä»ç¼“å­˜å–å‡ºå­å›¾
                with high_fps_cache_lock:
                    cached_frames = high_fps_subimage_cache.pop(request.image_audio_id, {})
                
                if len(cached_frames) > 0:
                    # æœ‰ç¼“å­˜çš„å­å›¾ï¼Œstack å prefill
                    sorted_frames = sorted(cached_frames.items(), key=lambda x: x[0])
                    subimages = [img for _, img in sorted_frames]
                    stacked_image = stack_images(subimages)
                    pil_images = [stacked_image]
                    print(f"[é«˜åˆ·æ¨¡å¼] éŸ³é¢‘åˆ°è¾¾ï¼Œå–å‡º {len(subimages)} å¸§å­å›¾ stackï¼Œprefill", flush=True)
                    
                    # å¦‚æœå½“å‰è¯·æ±‚ä¹Ÿå¸¦å›¾ç‰‡ï¼ˆä¸åº”è¯¥å‘ç”Ÿï¼Œä½†åšä¸ªä¿æŠ¤ï¼‰
                    if pil_image is not None:
                        pil_images.append(pil_image)
                else:
                    # æ²¡æœ‰ç¼“å­˜çš„å­å›¾ï¼Œæ£€æŸ¥å­å›¾æ˜¯å¦è¿˜æ²¡åˆ°é½
                    # ç¼“å­˜éŸ³é¢‘ï¼Œç­‰å­å›¾åˆ°é½
                    with high_fps_audio_lock:
                        high_fps_pending_audio[request.image_audio_id] = (audio_np, sr, None)
                    print(f"[é«˜åˆ·æ¨¡å¼] éŸ³é¢‘åˆ°è¾¾ä½†æ— å­å›¾ç¼“å­˜ï¼Œæš‚å­˜éŸ³é¢‘ç­‰å¾…å­å›¾ image_audio_id={request.image_audio_id}", flush=True)
                    return {
                        "success": True,
                        "message": f"éŸ³é¢‘å·²æš‚å­˜ï¼Œç­‰å¾…å­å›¾ (image_audio_id={request.image_audio_id})",
                        "mode": "high_fps_audio_pending"
                    }
        else:
            # éé«˜åˆ·æ¨¡å¼æˆ–æ²¡æœ‰ image_audio_idï¼šä½¿ç”¨åŸæœ‰é€»è¾‘
            pil_images = [pil_image] if pil_image is not None else []
        
        if audio_np is None and len(pil_images) == 0:
            raise HTTPException(status_code=400, detail="å¿…é¡»æä¾›éŸ³é¢‘æˆ–å›¾ç‰‡è‡³å°‘ä¸€é¡¹")
        
        audio_duration = len(audio_np) / sr if audio_np is not None else 0.0
        omni_mode = (current_msg_type == 2)
        
        # ========== æ ¹æ®æ¨¡å¼é€‰æ‹©ä¸åŒçš„å¤„ç†é€»è¾‘ ==========
        if current_duplex_mode:
            # ========== åŒå·¥æ¨¡å¼ï¼šç›´æ¥è½¬å‘ç»™ C++ ==========
            return await _streaming_prefill_duplex(
                request, audio_np, pil_images, sr, audio_duration, 
                omni_mode, timing_stats, prefill_start_time
            )
        elif current_high_fps_mode and current_msg_type == 2:
            # ========== é«˜åˆ·å•å·¥æ¨¡å¼ï¼šç›´æ¥ prefillï¼Œä¸å»¶è¿Ÿ ==========
            # é«˜åˆ·æ¨¡å¼åªå¯¹ omni æ¨¡å¼ï¼ˆæœ‰å›¾ç‰‡ï¼‰æœ‰æ„ä¹‰ï¼Œaudio æ¨¡å¼èµ°æ™®é€šå•å·¥è·¯å¾„
            # é«˜åˆ·æ¨¡å¼é€šè¿‡ image_audio_id ä¿è¯é…å¯¹ï¼Œä¸éœ€è¦"å»¶è¿Ÿä¸€æ‹"
            # ä¸»å›¾ç«‹å³ prefillï¼ŒéŸ³é¢‘+stackå›¾ä¹Ÿç«‹å³ prefill
            return await _streaming_prefill_highfps_direct(
                request, audio_np, pil_images, sr, audio_duration,
                omni_mode, timing_stats, prefill_start_time,
                is_main_image=is_main_image  # ğŸ”§ [é«˜æ¸…+é«˜åˆ·] ä¼ å…¥ä¸»å›¾æ ‡è®°
            )
        else:
            # ========== æ™®é€šå•å·¥æ¨¡å¼ï¼šä½¿ç”¨"å»¶è¿Ÿä¸€æ‹"æœºåˆ¶ ==========
            return await _streaming_prefill_simplex(
                request, audio_np, pil_images, sr, audio_duration,
                omni_mode, timing_stats, prefill_start_time
            )
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"é¢„å¡«å……å¤±è´¥: {str(e)}")


async def _streaming_prefill_duplex(
    request, audio_np, pil_images, sr, audio_duration, 
    omni_mode, timing_stats, prefill_start_time
):
    """åŒå·¥æ¨¡å¼çš„ streaming_prefill å®ç°ï¼šç›´æ¥è½¬å‘ç»™ C++"""
    global current_request_counter
    
    # å¢åŠ è¯·æ±‚è®¡æ•°ï¼Œè®¡ç®— cntï¼ˆä» 0 å¼€å§‹ï¼‰
    with session_lock:
        cnt = current_request_counter
        current_request_counter += 1
    
    # 3. ä¿å­˜éŸ³é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
    t0 = time.time()
    temp_audio_path = ""
    if audio_np is not None and len(audio_np) > 0:
        # éŸ³é¢‘å¤ªçŸ­æ—¶è¿›è¡Œ paddingï¼ˆæœ€å°‘ 0.1s = 1600 samplesï¼‰
        MIN_AUDIO_SAMPLES = 1600
        if len(audio_np) < MIN_AUDIO_SAMPLES:
            original_len = len(audio_np)
            padding_len = MIN_AUDIO_SAMPLES - original_len
            audio_np = np.pad(audio_np, (0, padding_len), mode='constant', constant_values=0)
        
        temp_audio_path = os.path.join(TEMP_DIR, f"prefill_{current_active_session_id}_{cnt}.wav")
        audio_to_save = np.clip(audio_np, -1.0, 1.0).astype(np.float32)
        sf.write(temp_audio_path, audio_to_save, 16000, format='WAV', subtype='PCM_16')
    timing_stats['audio_save'] = (time.time() - t0) * 1000
    
    # 4. å¤„ç†å›¾ç‰‡å¹¶ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
    t0 = time.time()
    temp_image_paths = []
    
    if len(pil_images) > 0:
        if current_high_fps_mode and len(pil_images) > 1:
            # é«˜åˆ·æ¨¡å¼ï¼šç¬¬1å¼ æ˜¯ä¸»å›¾ï¼Œåé¢çš„ stack æˆä¸€å¼ 
            main_image = pil_images[0]
            rest_images = pil_images[1:]
            
            main_path = os.path.join(TEMP_DIR, f"prefill_{current_active_session_id}_{cnt}_main.png")
            main_image.save(main_path, format='PNG')
            temp_image_paths.append(main_path)
            
            if len(rest_images) > 0:
                stacked_image = stack_images(rest_images)
                stack_path = os.path.join(TEMP_DIR, f"prefill_{current_active_session_id}_{cnt}_stack.png")
                stacked_image.save(stack_path, format='PNG')
                temp_image_paths.append(stack_path)
                print(f"[é«˜åˆ·æ¨¡å¼] å¤„ç† {len(pil_images)} å¸§ï¼Œä¸»å›¾1å¼  + stack {len(rest_images)} å¸§æˆ1å¼ ", flush=True)
        else:
            # æ™®é€šæ¨¡å¼ï¼šå•å¼ å›¾
            img_path = os.path.join(TEMP_DIR, f"prefill_{current_active_session_id}_{cnt}.png")
            pil_images[0].save(img_path, format='PNG')
            temp_image_paths.append(img_path)
    
    timing_stats['image_save'] = (time.time() - t0) * 1000
    
    # 5. è°ƒç”¨ C++ prefill
    t0 = time.time()
    cpp_success = True
    
    if len(temp_image_paths) == 0:
        # åªæœ‰éŸ³é¢‘ï¼Œæ²¡æœ‰å›¾ç‰‡
        cpp_request = {
            "audio_path_prefix": temp_audio_path,
            "img_path_prefix": "",
            "cnt": cnt
        }
        resp = await http_client.post(
            f"{CPP_SERVER_URL}/v1/stream/prefill",
            json=cpp_request,
            timeout=30.0
        )
        cpp_success = (resp.status_code == 200)
    else:
        # æœ‰å›¾ç‰‡ï¼šç¬¬ä¸€å¼ å›¾å’ŒéŸ³é¢‘ä¸€èµ·å‘ï¼Œåç»­å›¾ç‰‡å•ç‹¬å‘
        for i, img_path in enumerate(temp_image_paths):
            cpp_request = {
                "audio_path_prefix": temp_audio_path if i == 0 else "",
                "img_path_prefix": img_path,
                "cnt": cnt + i
            }
            resp = await http_client.post(
                f"{CPP_SERVER_URL}/v1/stream/prefill",
                json=cpp_request,
                timeout=30.0
            )
            if resp.status_code != 200:
                cpp_success = False
                break
        
        # æ›´æ–° counter
        with session_lock:
            current_request_counter += len(temp_image_paths) - 1
    
    timing_stats['cpp_http'] = (time.time() - t0) * 1000
    
    total_prefill_time = (time.time() - prefill_start_time) * 1000
    timing_stats['total'] = total_prefill_time
    
    # æ‰“å°æ€§èƒ½ç»Ÿè®¡
    num_images = len(temp_image_paths)
    has_image = f"âœ“({num_images}å¼ )" if num_images > 0 else "âœ—"
    if cpp_success:
        print(f"[Prefill #{cnt}] âœ“ {total_prefill_time:.0f}ms (éŸ³é¢‘:{audio_duration:.2f}s å›¾ç‰‡:{has_image}) [åŒå·¥]", flush=True)
    else:
        print(f"[Prefill #{cnt}] âœ— C++ prefill å¤±è´¥ [åŒå·¥]", flush=True)
    
    # ğŸ”§ æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆC++ å·²è¯»å–å®Œæ¯•ï¼Œä¸å†éœ€è¦ï¼‰
    try:
        if temp_audio_path and os.path.exists(temp_audio_path):
            os.remove(temp_audio_path)
        for img_path in temp_image_paths:
            if os.path.exists(img_path):
                os.remove(img_path)
    except Exception:
        pass
    
    return {
        "success": cpp_success,
        "session_id": current_active_session_id,
        "cnt": cnt,
        "audio_duration_seconds": float(audio_duration),
        "timing": timing_stats,
        "backend": "cpp_duplex"
    }


async def _streaming_prefill_highfps_direct(
    request, audio_np, pil_images, sr, audio_duration,
    omni_mode, timing_stats, prefill_start_time,
    is_main_image: bool = False  # ğŸ”§ [é«˜æ¸…+é«˜åˆ·] æ ‡è®°æ˜¯å¦ä¸ºä¸»å›¾ï¼ˆå†³å®šæ˜¯å¦ä½¿ç”¨é«˜æ¸…åˆ‡ç‰‡ï¼‰
):
    """é«˜åˆ·å•å·¥æ¨¡å¼çš„ streaming_prefill å®ç°ï¼šç›´æ¥ prefillï¼Œä¸å»¶è¿Ÿ
    
    é«˜åˆ·æ¨¡å¼é€šè¿‡ image_audio_id ä¿è¯æ•°æ®é…å¯¹ï¼Œä¸éœ€è¦"å»¶è¿Ÿä¸€æ‹"æœºåˆ¶ã€‚
    - ä¸»å›¾åˆ°è¾¾ï¼šç«‹å³ prefill ä¸»å›¾ï¼ˆæ— éŸ³é¢‘ï¼‰ï¼Œå¦‚æœå¼€å¯é«˜æ¸…åˆ™ max_slice_nums=2
    - éŸ³é¢‘+stackå›¾åˆ°è¾¾ï¼šç«‹å³ prefill stackå›¾+éŸ³é¢‘ï¼Œmax_slice_nums=1ï¼ˆä¸åˆ‡ç‰‡ï¼‰
    """
    global current_request_counter
    
    # å¢åŠ è¯·æ±‚è®¡æ•°
    with session_lock:
        cnt = current_request_counter
        current_request_counter += 1
    
    # ä¿å­˜éŸ³é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
    t0 = time.time()
    temp_audio_path = ""
    if audio_np is not None and len(audio_np) > 0:
        # éŸ³é¢‘å¤ªçŸ­æ—¶è¿›è¡Œ paddingï¼ˆæœ€å°‘ 0.1s = 1600 samplesï¼‰
        MIN_AUDIO_SAMPLES = 1600
        if len(audio_np) < MIN_AUDIO_SAMPLES:
            padding_len = MIN_AUDIO_SAMPLES - len(audio_np)
            audio_np = np.pad(audio_np, (0, padding_len), mode='constant', constant_values=0)
        
        temp_audio_path = os.path.join(TEMP_DIR, f"prefill_{current_active_session_id}_{cnt}.wav")
        audio_to_save = np.clip(audio_np, -1.0, 1.0).astype(np.float32)
        sf.write(temp_audio_path, audio_to_save, 16000, format='WAV', subtype='PCM_16')
    timing_stats['audio_save'] = (time.time() - t0) * 1000
    
    # ä¿å­˜å›¾ç‰‡åˆ°ä¸´æ—¶æ–‡ä»¶
    t0 = time.time()
    temp_image_paths = []
    
    if len(pil_images) > 0:
        for i, img in enumerate(pil_images):
            img_path = os.path.join(TEMP_DIR, f"prefill_{current_active_session_id}_{cnt}_{i}.png")
            img.save(img_path, format='PNG')
            temp_image_paths.append(img_path)
    
    timing_stats['image_save'] = (time.time() - t0) * 1000
    
    # è°ƒç”¨ C++ prefill
    t0 = time.time()
    cpp_success = True
    
    # ğŸ”§ [é«˜æ¸…+é«˜åˆ·] æ ¹æ® is_main_image å†³å®š max_slice_nums
    # ä¸»å›¾ä¸”é«˜æ¸…å¼€å¯ï¼šmax_slice_nums=2ï¼ˆåˆ‡ç‰‡ï¼‰
    # Stacked å›¾æˆ–æ™®é€šæ¨¡å¼ï¼šmax_slice_nums=1ï¼ˆä¸åˆ‡ç‰‡ï¼‰
    if is_main_image and current_high_quality_mode:
        slice_nums = 2  # ä¸»å›¾ä½¿ç”¨é«˜æ¸…åˆ‡ç‰‡
        slice_desc = "é«˜æ¸…"
    else:
        slice_nums = 1  # Stacked å›¾ä¸åˆ‡ç‰‡
        slice_desc = "æ™®é€š"
    
    if len(temp_image_paths) == 0:
        # åªæœ‰éŸ³é¢‘ï¼Œæ²¡æœ‰å›¾ç‰‡ï¼ˆä¸å¤ªå¯èƒ½åœ¨é«˜åˆ·æ¨¡å¼ä¸‹å‘ç”Ÿï¼‰
        cpp_request = {
            "audio_path_prefix": temp_audio_path,
            "img_path_prefix": "",
            "cnt": cnt
        }
        resp = await http_client.post(
            f"{CPP_SERVER_URL}/v1/stream/prefill",
            json=cpp_request,
            timeout=30.0
        )
        cpp_success = (resp.status_code == 200)
    else:
        # æœ‰å›¾ç‰‡ï¼šå›¾ç‰‡å’ŒéŸ³é¢‘ä¸€èµ·å‘
        for i, img_path in enumerate(temp_image_paths):
            cpp_request = {
                "audio_path_prefix": temp_audio_path if i == 0 else "",
                "img_path_prefix": img_path,
                "cnt": cnt + i,
                "max_slice_nums": slice_nums  # ğŸ”§ [é«˜æ¸…+é«˜åˆ·] ä¼ å…¥åˆ‡ç‰‡å‚æ•°
            }
            resp = await http_client.post(
                f"{CPP_SERVER_URL}/v1/stream/prefill",
                json=cpp_request,
                timeout=30.0
            )
            if resp.status_code != 200:
                cpp_success = False
                break
        
        # æ›´æ–° counter
        with session_lock:
            current_request_counter += len(temp_image_paths) - 1
    
    timing_stats['cpp_http'] = (time.time() - t0) * 1000
    
    total_prefill_time = (time.time() - prefill_start_time) * 1000
    timing_stats['total'] = total_prefill_time
    
    # æ‰“å°æ€§èƒ½ç»Ÿè®¡
    num_images = len(temp_image_paths)
    has_image = f"âœ“({num_images}å¼ )" if num_images > 0 else "âœ—"
    has_audio = f"{audio_duration:.2f}s" if audio_duration > 0 else "æ— "
    img_type = "ä¸»å›¾" if is_main_image else "Stackedå›¾"
    if cpp_success:
        print(f"[Prefill #{cnt}] âœ“ {total_prefill_time:.0f}ms (éŸ³é¢‘:{has_audio} å›¾ç‰‡:{has_image} {img_type}/{slice_desc}) [é«˜åˆ·å•å·¥]", flush=True)
    else:
        print(f"[Prefill #{cnt}] âœ— C++ prefill å¤±è´¥ (status={resp.status_code if 'resp' in dir() else 'N/A'}) [é«˜åˆ·å•å·¥]", flush=True)
    
    # ğŸ”§ æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆC++ å·²è¯»å–å®Œæ¯•ï¼Œä¸å†éœ€è¦ï¼‰
    try:
        if temp_audio_path and os.path.exists(temp_audio_path):
            os.remove(temp_audio_path)
        for img_path in temp_image_paths:
            if os.path.exists(img_path):
                os.remove(img_path)
    except Exception:
        pass
    
    return {
        "success": cpp_success,
        "session_id": current_active_session_id,
        "cnt": cnt,
        "audio_duration_seconds": float(audio_duration),
        "timing": timing_stats,
        "backend": "cpp_highfps_simplex"
    }


async def _streaming_prefill_simplex(
    request, audio_np, pil_images, sr, audio_duration,
    omni_mode, timing_stats, prefill_start_time
):
    """æ™®é€šå•å·¥æ¨¡å¼çš„ streaming_prefill å®ç°ï¼šä½¿ç”¨"å»¶è¿Ÿä¸€æ‹"æœºåˆ¶"""
    global pending_prefill_data, current_request_counter
    
    # å¢åŠ è¯·æ±‚è®¡æ•°
    with session_lock:
        current_request_counter += 1
        request_idx = current_request_counter
    
    # ã€å»¶è¿Ÿä¸€æ‹ã€‘å…ˆå¤„ç†ä¸Šä¸€æ¬¡ç¼“å­˜çš„æ•°æ®
    model_prefill_start = time.time()
    if pending_prefill_data is not None:
        prev_data = pending_prefill_data
        prev_images = prev_data.get("images", [])
        prev_audio = prev_data["audio_np"]
        has_prev_audio = prev_audio is not None and len(prev_audio) > 0
        has_prev_images = len(prev_images) > 0
        
        # ğŸ”§ [é«˜åˆ·ä¿®å¤] åªè¦æœ‰éŸ³é¢‘æˆ–å›¾ç‰‡ï¼Œå°±å¤„ç†ä¸Šä¸€æ¬¡çš„ç¼“å­˜æ•°æ®
        if has_prev_audio or has_prev_images:
            prev_cnt = prev_data["cnt"]
            
            # å¤„ç†éŸ³é¢‘
            temp_audio_path = ""
            if has_prev_audio:
                temp_audio_path = os.path.join(TEMP_DIR, f"prefill_{current_active_session_id}_{prev_cnt}.wav")
                audio_to_save = np.clip(prev_audio, -1.0, 1.0).astype(np.float32)
                sf.write(temp_audio_path, audio_to_save, 16000, format='WAV', subtype='PCM_16')
            
            # å¤„ç†å›¾ç‰‡åˆ—è¡¨
            temp_image_paths = []
            
            if has_prev_images:
                if current_high_fps_mode and len(prev_images) > 1:
                    main_image = prev_images[0]
                    rest_images = prev_images[1:]
                    
                    main_path = os.path.join(TEMP_DIR, f"prefill_{current_active_session_id}_{prev_cnt}_main.png")
                    main_image.save(main_path, format='PNG')
                    temp_image_paths.append(main_path)
                    
                    if len(rest_images) > 0:
                        stacked_image = stack_images(rest_images)
                        stack_path = os.path.join(TEMP_DIR, f"prefill_{current_active_session_id}_{prev_cnt}_stack.png")
                        stacked_image.save(stack_path, format='PNG')
                        temp_image_paths.append(stack_path)
                else:
                    for i, img in enumerate(prev_images):
                        img_path = os.path.join(TEMP_DIR, f"prefill_{current_active_session_id}_{prev_cnt}_{i}.png")
                        img.save(img_path, format='PNG')
                        temp_image_paths.append(img_path)
            
            # è°ƒç”¨ C++ prefill
            if len(temp_image_paths) == 0:
                cpp_request = {
                    "audio_path_prefix": temp_audio_path,
                    "img_path_prefix": "",
                    "cnt": prev_cnt
                }
                await http_client.post(f"{CPP_SERVER_URL}/v1/stream/prefill", json=cpp_request)
            else:
                for i, img_path in enumerate(temp_image_paths):
                    cpp_request = {
                        "audio_path_prefix": temp_audio_path if i == 0 else "",
                        "img_path_prefix": img_path,
                        "cnt": prev_cnt + i
                    }
                    await http_client.post(f"{CPP_SERVER_URL}/v1/stream/prefill", json=cpp_request)
            
            print(f"[å»¶è¿Ÿä¸€æ‹] å¤„ç†äº†ä¸Šä¸€æ¬¡ç¼“å­˜çš„ prefill æ•°æ® (cnt={prev_cnt}) [å•å·¥]", flush=True)
    else:
        print(f"[å»¶è¿Ÿä¸€æ‹] é¦–æ¬¡ prefillï¼Œæ— ç¼“å­˜æ•°æ® [å•å·¥]", flush=True)
    
    # è®¡ç®—å½“å‰æ•°æ®çš„ cnt
    current_cnt = request_idx - 1
    
    # ç¼“å­˜å½“å‰æ•°æ®
    pending_prefill_data = {
        "audio_np": audio_np,
        "images": pil_images,
        "omni_mode": omni_mode,
        "audio_duration": audio_duration,
        "request_idx": request_idx,
        "cnt": current_cnt,
    }
    num_imgs = len(pil_images)
    print(f"[å»¶è¿Ÿä¸€æ‹] å½“å‰æ•°æ®å·²ç¼“å­˜ (éŸ³é¢‘: {audio_duration:.2f}s, å›¾ç‰‡: {num_imgs}å¼ , cnt={current_cnt}) [å•å·¥]", flush=True)
    print(f"[ğŸ”” æé†’] ç¼“å­˜æ•°æ®ç­‰å¾… streaming_generate è°ƒç”¨å¤„ç† [å•å·¥]", flush=True)
    
    model_prefill_time = (time.time() - model_prefill_start) * 1000
    total_prefill_time = (time.time() - prefill_start_time) * 1000
    
    return {
        "success": True,
        "session_id": current_active_session_id,
        "request_idx": request_idx,
        "audio_duration_seconds": float(audio_duration),
        "timing": {
            "audio_decode_ms": round(timing_stats.get('audio_decode', 0), 1),
            "image_decode_ms": round(timing_stats.get('image_decode', 0), 1),
            "model_prefill_ms": round(model_prefill_time, 1),
            "total_ms": round(total_prefill_time, 1),
            "rtf": round(total_prefill_time / 1000 / audio_duration, 2) if audio_duration > 0 else None
        },
        "backend": "cpp_simplex"
    }


@app.post("/omni/streaming_generate")
async def streaming_generate():
    """æµå¼ç”Ÿæˆ
    
    æ ¹æ® duplex_mode ä½¿ç”¨ä¸åŒçš„å¤„ç†é€»è¾‘ï¼š
    - å•å·¥æ¨¡å¼ï¼šæ¯ä¸ª round æœ‰ç‹¬ç«‹ç›®å½•
    - åŒå·¥æ¨¡å¼ï¼šå…¨å±€ WAV è®¡æ•°å™¨ï¼Œä½¿ç”¨ SSE æµå¼è¯»å–
    """
    global pending_prefill_data, current_round_number, is_breaking
    
    # ğŸ”§ [ä¿®å¤] æ£€æŸ¥æ˜¯å¦æ­£åœ¨é‡å¯
    if cpp_restarting:
        raise HTTPException(status_code=503, detail="æœåŠ¡æ­£åœ¨é‡å¯ä¸­ï¼Œè¯·ç¨åé‡è¯•")
    
    if not current_active_session_id:
        raise HTTPException(
            status_code=400,
            detail="æœªæ‰¾åˆ°æ´»è·ƒä¼šè¯ï¼Œè¯·å…ˆè°ƒç”¨ /omni/init_sys_prompt åˆå§‹åŒ–ä¼šè¯"
        )
    
    # ã€é‡ç½® break æ ‡å¿—ã€‘å¼€å§‹æ–°ä¸€è½®ç”Ÿæˆæ—¶ï¼Œé‡ç½® is_breaking
    is_breaking = False
    
    generate_request_time = time.time()
    print(f"[Generate] å¼€å§‹ç”Ÿæˆ (Round #{current_round_number}, duplex_mode={current_duplex_mode})", flush=True)
    
    # æ ¹æ®æ¨¡å¼é€‰æ‹©ä¸åŒçš„å®ç°
    if current_duplex_mode:
        return await _streaming_generate_duplex(generate_request_time)
    else:
        return await _streaming_generate_simplex(generate_request_time)


async def _streaming_generate_simplex(generate_request_time):
    """å•å·¥æ¨¡å¼çš„ streaming_generate å®ç°"""
    global pending_prefill_data, current_round_number, is_breaking
    
    # ğŸ”§ [è¯Šæ–­] è®°å½• generate è°ƒç”¨æ—¶çš„çŠ¶æ€
    has_pending = pending_prefill_data is not None
    pending_cnt = pending_prefill_data.get("cnt", -1) if has_pending else -1
    print(f"[streaming_generate] å¼€å§‹, pending_data={has_pending}, pending_cnt={pending_cnt}, round={current_round_number} [å•å·¥]", flush=True)
    
    # ã€å»¶è¿Ÿä¸€æ‹ã€‘å¤„ç†ç¼“å­˜çš„æœ€åä¸€ç‰‡æ•°æ®
    if pending_prefill_data is not None:
        try:
            print("[streaming_generate] å¤„ç†ç¼“å­˜çš„æœ€åä¸€ç‰‡æ•°æ® (is_last_chunk=True)... [å•å·¥]", flush=True)
            last_data = pending_prefill_data
            
            audio_np = last_data["audio_np"]
            if audio_np is not None and len(audio_np) > 0:
                MIN_AUDIO_SAMPLES = 1600
                if len(audio_np) < MIN_AUDIO_SAMPLES:
                    original_len = len(audio_np)
                    padding_len = MIN_AUDIO_SAMPLES - original_len
                    audio_np = np.pad(audio_np, (0, padding_len), mode='constant', constant_values=0)
                    print(f"[éŸ³é¢‘Padding] {original_len} -> {MIN_AUDIO_SAMPLES} samples", flush=True)
                
                last_cnt = last_data["cnt"]
                temp_audio_path = os.path.join(TEMP_DIR, f"prefill_{current_active_session_id}_{last_cnt}.wav")
                audio_to_save = np.clip(audio_np, -1.0, 1.0).astype(np.float32)
                sf.write(temp_audio_path, audio_to_save, 16000, format='WAV', subtype='PCM_16')
                
                temp_image_path = ""
                images = last_data.get("images", [])
                if len(images) > 0:
                    temp_image_path = os.path.join(TEMP_DIR, f"prefill_{current_active_session_id}_{last_cnt}.png")
                    images[0].save(temp_image_path, format='PNG')
                
                cpp_request = {
                    "audio_path_prefix": temp_audio_path,
                    "img_path_prefix": temp_image_path,
                    "cnt": last_cnt
                }
                
                resp = await http_client.post(
                    f"{CPP_SERVER_URL}/v1/stream/prefill",
                    json=cpp_request
                )
                
                if resp.status_code != 200:
                    print(f"C++ æœ€åä¸€ç‰‡ prefill å¤±è´¥: {resp.text}", flush=True)
                else:
                    print(f"[streaming_generate] æœ€åä¸€ç‰‡ prefill æˆåŠŸ (cnt={last_cnt}) [å•å·¥]", flush=True)
            
            pending_prefill_data = None
            print("[streaming_generate] æœ€åä¸€ç‰‡å·²å¤„ç† [å•å·¥]", flush=True)
            
        except Exception as e:
            print(f"[streaming_generate] å¤„ç†æœ€åä¸€ç‰‡å¤±è´¥: {e}", flush=True)
            pending_prefill_data = None
    
    # è¾“å‡ºç›®å½•ï¼ˆå•å·¥æ¨¡å¼ï¼šæ¯ä¸ª round æœ‰ç‹¬ç«‹ç›®å½•ï¼‰
    output_dir = os.path.join(TEMP_DIR, f"session_{current_active_session_id}", f"round_{current_round_number:04d}", "output")
    os.makedirs(output_dir, exist_ok=True)
    
    async def generate_stream():
        global current_round_number
        import re
        
        generate_start_time = time.time()
        first_chunk_time = None
        first_text_time = None
        chunk_durations = []
        sent_chunk_count = 0
        last_text_len = 0
        sr = 24000
        
        def sort_wav_files(files):
            def extract_num(f):
                match = re.search(r'wav_(\d+)\.wav', f)
                return int(match.group(1)) if match else 0
            return sorted(files, key=extract_num)
        
        try:
            cpp_request = {
                "debug_dir": output_dir,
                "stream": True,
                "round_idx": current_round_number
            }
            
            print(f"[streaming_generate] è°ƒç”¨ C++ decode: {json.dumps(cpp_request)} [å•å·¥]", flush=True)
            
            decode_task = asyncio.create_task(
                http_client.post(
                    f"{CPP_SERVER_URL}/v1/stream/decode",
                    json=cpp_request,
                    timeout=600.0
                )
            )
            
            cpp_output_base = CPP_OUTPUT_DIR
            round_dir = os.path.join(cpp_output_base, f"round_{current_round_number:03d}")
            tts_wav_dir = os.path.join(round_dir, "tts_wav")
            llm_debug_dir = os.path.join(round_dir, "llm_debug")
            
            print(f"[streaming_generate] å½“å‰è½®æ¬¡: {current_round_number} [å•å·¥]", flush=True)
            print(f"  WAV ç›®å½•: {tts_wav_dir}", flush=True)
            
            max_wait = 1800
            check_interval = 0.01
            no_new_wav_count = 0
            max_no_new_wav = 1000
            decode_done = False
            chunk_texts = {}
            all_generated_text = []
            existing_wav_files = set()
            sent_wav_files = set()
            llm_chunk_idx = 0
            
            if os.path.exists(tts_wav_dir):
                existing_wav_files = set(f for f in os.listdir(tts_wav_dir) if f.startswith("wav_") and f.endswith(".wav"))
            
            def read_chunk_text(llm_debug_dir, chunk_idx):
                chunk_dir = os.path.join(llm_debug_dir, f"chunk_{chunk_idx}")
                text_file = os.path.join(chunk_dir, "llm_text.txt")
                if os.path.exists(text_file):
                    try:
                        with open(text_file, 'r', encoding='utf-8', errors='ignore') as f:
                            return f.read().strip()
                    except:
                        pass
                return ""
            
            for _ in range(int(max_wait / check_interval)):
                await asyncio.sleep(check_interval)
                
                if is_breaking:
                    print(f"[streaming_generate] æ£€æµ‹åˆ° break æ ‡å¿—ï¼Œåœæ­¢å‘é€æ•°æ® [å•å·¥]", flush=True)
                    yield f"data: {json.dumps({'break': True, 'done': True, 'message': 'ç”¨æˆ·æ‰“æ–­'}, ensure_ascii=False)}\n\n"
                    break
                
                if decode_task.done() and not decode_done:
                    decode_done = True
                    try:
                        resp = decode_task.result()
                        if resp.status_code != 200:
                            print(f"[streaming_generate] C++ decode è¿”å›é”™è¯¯: {resp.text}", flush=True)
                        else:
                            print(f"[streaming_generate] C++ decode å®Œæˆ [å•å·¥]", flush=True)
                    except Exception as e:
                        print(f"[streaming_generate] C++ decode å¼‚å¸¸: {e}", flush=True)
                
                if os.path.exists(tts_wav_dir):
                    wav_files = [f for f in os.listdir(tts_wav_dir) if f.startswith("wav_") and f.endswith(".wav")]
                    wav_files = sort_wav_files(wav_files)
                    
                    new_wav_files = [f for f in wav_files if f not in existing_wav_files and f not in sent_wav_files]
                    
                    for wav_file in new_wav_files:
                        wav_path = os.path.join(tts_wav_dir, wav_file)
                        
                        if not os.path.exists(wav_path):
                            await asyncio.sleep(0.05)
                            if not os.path.exists(wav_path):
                                continue
                        
                        match = re.search(r'wav_(\d+)\.wav', wav_file)
                        chunk_idx = int(match.group(1)) if match else sent_chunk_count
                        
                        try:
                            await asyncio.sleep(0.01)
                            
                            audio_data, audio_sr = sf.read(wav_path)
                            
                            if len(audio_data) == 0:
                                sent_wav_files.add(wav_file)
                                continue
                            
                            if first_chunk_time is None:
                                first_chunk_time = (time.time() - generate_start_time) * 1000
                                print(f"[â±ï¸ Generate éŸ³é¢‘é¦–å“] {first_chunk_time:.1f}ms [å•å·¥]", flush=True)
                            
                            if audio_data.dtype != np.int16:
                                audio_data = (audio_data * 32767).astype(np.int16)
                            wav_base64 = base64.b64encode(audio_data.tobytes()).decode('utf-8')
                            
                            chunk_duration = len(audio_data) / audio_sr
                            chunk_durations.append(chunk_duration)
                            
                            if chunk_idx not in chunk_texts and os.path.exists(llm_debug_dir):
                                chunk_text = read_chunk_text(llm_debug_dir, llm_chunk_idx)
                                if chunk_text:
                                    chunk_texts[chunk_idx] = chunk_text
                                    all_generated_text.append(chunk_text)
                                    llm_chunk_idx += 1
                                    if first_text_time is None:
                                        first_text_time = (time.time() - generate_start_time) * 1000
                                        print(f"[â±ï¸ Generate æ–‡æœ¬é¦–å“] {first_text_time:.1f}ms [å•å·¥]", flush=True)
                            
                            chunk_data = {
                                "chunk_idx": sent_chunk_count,
                                "chunk_data": {
                                    "wav": wav_base64,
                                    "sample_rate": int(audio_sr)
                                }
                            }
                            
                            if chunk_idx in chunk_texts:
                                chunk_data["chunk_data"]["text"] = chunk_texts[chunk_idx]
                                last_text_len += len(chunk_texts[chunk_idx])
                                print(f"[Chunk #{chunk_idx}] å‘é€ {wav_file} ({chunk_duration:.3f}s) + æ–‡æœ¬ [å•å·¥]", flush=True)
                            else:
                                print(f"[Chunk #{chunk_idx}] å‘é€ {wav_file} ({chunk_duration:.3f}s) [å•å·¥]", flush=True)
                            
                            yield f"data: {json.dumps(chunk_data, ensure_ascii=False)}\n\n"
                            
                            sent_wav_files.add(wav_file)
                            sent_chunk_count += 1
                            
                        except FileNotFoundError:
                            print(f"[Chunk #{chunk_idx}] æ–‡ä»¶å°šæœªå°±ç»ªï¼Œç¨åé‡è¯• [å•å·¥]", flush=True)
                        except Exception as e:
                            print(f"[Chunk #{chunk_idx}] è¯»å–å¤±è´¥: {e} [å•å·¥]", flush=True)
                            sent_wav_files.add(wav_file)
                    
                    # æ£€æŸ¥ç»“æŸæ ‡è®°
                    done_flag_path = os.path.join(tts_wav_dir, "generation_done.flag")
                    if os.path.exists(done_flag_path):
                        try:
                            with open(done_flag_path, 'r') as f:
                                last_wav_idx = int(f.read().strip())
                            last_wav_file = f"wav_{last_wav_idx}.wav"
                            if last_wav_file in sent_wav_files or last_wav_file in existing_wav_files:
                                print(f"[streaming_generate] æ‰€æœ‰ wav å·²å‘é€ï¼Œç«‹å³ç»“æŸ [å•å·¥]", flush=True)
                                break
                        except:
                            pass
                    
                    current_new_count = len([f for f in wav_files if f not in existing_wav_files])
                    if current_new_count == len(sent_wav_files):
                        no_new_wav_count += 1
                        if decode_done and no_new_wav_count >= 30000:
                            print(f"[streaming_generate] è¶…æ—¶é€€å‡º [å•å·¥]", flush=True)
                            break
                    else:
                        no_new_wav_count = 0
                
                if decode_done and sent_chunk_count == 0:
                    no_new_wav_count += 1
                    if no_new_wav_count >= max_no_new_wav:
                        print(f"[streaming_generate] decodeå®Œæˆä½†æ— wavè¾“å‡ºï¼Œè¶…æ—¶é€€å‡º [å•å·¥]", flush=True)
                        break
            
            if not decode_task.done():
                print("[streaming_generate] ç­‰å¾… C++ decode å®Œæˆ... [å•å·¥]", flush=True)
                try:
                    await asyncio.wait_for(decode_task, timeout=30.0)
                except asyncio.TimeoutError:
                    print("[streaming_generate] C++ decode è¶…æ—¶ [å•å·¥]", flush=True)
            
            if all_generated_text:
                full_text = "".join(all_generated_text)
                print(f"\n[ğŸ“ å®Œæ•´ç”Ÿæˆæ–‡æœ¬] {full_text}\n", flush=True)
            
            total_generate_time = (time.time() - generate_start_time) * 1000
            total_audio_duration = sum(chunk_durations) if chunk_durations else 0
            overall_rtf = total_generate_time / 1000 / total_audio_duration if total_audio_duration > 0 else 0
            
            print(f"\n{'='*60}", flush=True)
            print(f"[â±ï¸ Generate æ€§èƒ½æ€»ç»“] [å•å·¥]", flush=True)
            print(f"  éŸ³é¢‘é¦–å“: {first_chunk_time:.1f}ms" if first_chunk_time else "  éŸ³é¢‘é¦–å“: N/A", flush=True)
            print(f"  æ€»ç”Ÿæˆæ—¶é—´: {total_generate_time:.1f}ms", flush=True)
            print(f"  æ€»éŸ³é¢‘æ—¶é•¿: {total_audio_duration:.2f}s", flush=True)
            print(f"  æ•´ä½“ RTF: {overall_rtf:.2f}x {'âœ…' if overall_rtf < 1.0 else 'âš ï¸'}", flush=True)
            print(f"  å‘é€ Chunk æ•°é‡: {sent_chunk_count}", flush=True)
            print(f"{'='*60}\n", flush=True)
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            print(f"[streaming_generate] å¼‚å¸¸: {e}\n{error_detail} [å•å·¥]", flush=True)
            yield f"data: {json.dumps({'error': str(e)}, ensure_ascii=False)}\n\n"
        
        with session_lock:
            current_round_number += 1
            # ğŸ”§ [ä¿®å¤å¤šè½® user prompt] æ¯è½®ç»“æŸåé‡ç½® prefill è®¡æ•°å™¨
            # è¿™æ ·ä¸‹ä¸€è½®çš„ prefill ä¼šä» cnt=0 å¼€å§‹ï¼ŒC++ ç«¯èƒ½æ­£ç¡®è¯†åˆ«æ–°ä¸€è½®çš„å¼€å§‹
            global current_request_counter
            current_request_counter = 0
        
        # æ¨ç†ç»“æŸåï¼Œåœ¨åå°æ£€æŸ¥æ˜¾å­˜å¹¶åœ¨éœ€è¦æ—¶é‡å¯
        def background_memory_check():
            time.sleep(1.0)  # ç­‰å¾…ä¸€ä¼šå„¿è®©å½“å‰è¯·æ±‚å®Œå…¨ç»“æŸ
            if check_gpu_memory_and_restart_if_needed():
                print("[å•å·¥] æ˜¾å­˜ä¸è¶³ï¼Œå·²åœ¨åå°è§¦å‘é‡å¯", flush=True)
        
        threading.Thread(target=background_memory_check, daemon=True).start()
        
        yield f"data: {json.dumps({'done': True}, ensure_ascii=False)}\n\n"
    
    return StreamingResponse(
        generate_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
        }
    )


async def _streaming_generate_duplex(generate_request_time):
    """åŒå·¥æ¨¡å¼çš„ streaming_generate å®ç°"""
    global current_round_number, is_breaking
    global global_sent_wav_count, global_parsed_line_count, global_parsed_texts, global_text_send_idx, global_sent_wav_files
    global wav_timing_log_file, last_wav_send_time
    
    output_dir = os.path.join(TEMP_DIR, f"session_{current_active_session_id}", f"round_{current_round_number:04d}", "output")
    os.makedirs(output_dir, exist_ok=True)
    
    async def generate_stream():
        global current_round_number, global_sent_wav_count, global_parsed_line_count
        global global_parsed_texts, global_text_send_idx, is_breaking, global_sent_wav_files
        global wav_timing_log_file, last_wav_send_time
        import re
        
        generate_start_time = time.time()
        setup_time = (generate_start_time - generate_request_time) * 1000
        if setup_time > 10:
            print(f"[Generate] âš ï¸ è¯·æ±‚å¤„ç†å»¶è¿Ÿ: {setup_time:.0f}ms [åŒå·¥]", flush=True)
        first_chunk_time = None
        first_text_time = None
        chunk_durations = []
        sent_chunk_count = global_sent_wav_count
        last_text_len = 0
        is_listen = True
        
        def sort_wav_files(files):
            def extract_num(f):
                match = re.search(r'wav_(\d+)\.wav', f)
                return int(match.group(1)) if match else 0
            return sorted(files, key=extract_num)
        
        try:
            cpp_request = {
                "debug_dir": "./tools/omni/output",
                "stream": True
            }
            
            print(f"[streaming_generate] è°ƒç”¨ C++ decode: {json.dumps(cpp_request)} [åŒå·¥]", flush=True)
            
            # ğŸ”§ [å¤šå®ä¾‹æ”¯æŒ] ä½¿ç”¨é…ç½®çš„è¾“å‡ºç›®å½•
            cpp_output_base = CPP_OUTPUT_DIR
            tts_wav_dir = os.path.join(cpp_output_base, "tts_wav")
            llm_debug_dir = os.path.join(cpp_output_base, "llm_debug")
            
            all_generated_text = []
            end_of_turn = False
            
            def parse_llm_text_file():
                global global_parsed_line_count, global_parsed_texts
                text_file = os.path.join(llm_debug_dir, "llm_text.txt")
                new_count = 0
                if os.path.exists(text_file):
                    try:
                        with open(text_file, 'r', encoding='utf-8', errors='ignore') as f:
                            lines = f.readlines()
                        
                        for line in lines[global_parsed_line_count:]:
                            line = line.strip()
                            if not line:
                                continue
                            match = re.match(r'\[chunk_\d+\]\s*(.*)', line)
                            if match:
                                text = match.group(1).strip()
                                if text:
                                    global_parsed_texts.append(text)
                                    new_count += 1
                            else:
                                global_parsed_texts.append(line)
                                new_count += 1
                        
                        global_parsed_line_count = len(lines)
                    except Exception as e:
                        print(f"[Parse LLM Text] è§£æå¤±è´¥: {e} [åŒå·¥]", flush=True)
                return new_count
            
            def init_wav_timing_log():
                global wav_timing_log_file
                if wav_timing_log_file is None:
                    wav_timing_log_file = open(WAV_TIMING_LOG_PATH, 'a', encoding='utf-8')
                    wav_timing_log_file.write(f"\n{'='*80}\n")
                    wav_timing_log_file.write(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')}] æ–°ä¼šè¯å¼€å§‹ (åŒå·¥æ¨¡å¼)\n")
                    wav_timing_log_file.write(f"{'='*80}\n")
                    wav_timing_log_file.flush()
            
            print(f"[streaming_generate] å¼€å§‹ç›‘æ§ [åŒå·¥]:", flush=True)
            print(f"  WAVç›®å½•: {tts_wav_dir}", flush=True)
            
            wav_queue = asyncio.Queue()
            stop_wav_scanner = asyncio.Event()
            
            async def wav_scanner_coroutine():
                global last_wav_send_time, wav_timing_log_file, global_parsed_texts, global_text_send_idx, global_sent_wav_files
                nonlocal sent_chunk_count, first_chunk_time, first_text_time, last_text_len
                scan_interval = 0.05
                
                while not stop_wav_scanner.is_set():
                    try:
                        if not os.path.exists(tts_wav_dir):
                            await asyncio.sleep(scan_interval)
                            continue
                        
                        new_count = parse_llm_text_file()
                        if new_count > 0:
                            new_texts = global_parsed_texts[-new_count:]
                            all_generated_text.extend(new_texts)
                            if first_text_time is None and global_parsed_texts:
                                first_text_time = (time.time() - generate_start_time) * 1000
                                print(f"[â±ï¸ Generate æ–‡æœ¬é¦–å“] {first_text_time:.1f}ms [åŒå·¥]", flush=True)
                        
                        wav_files = [f for f in os.listdir(tts_wav_dir) if f.startswith("wav_") and f.endswith(".wav")]
                        wav_files = sort_wav_files(wav_files)
                        
                        new_wav_files = [f for f in wav_files if f not in global_sent_wav_files]
                        
                        for wav_file in new_wav_files:
                            if wav_file in global_sent_wav_files:
                                continue
                            global_sent_wav_files.add(wav_file)
                            
                            wav_path = os.path.join(tts_wav_dir, wav_file)
                            match = re.search(r'wav_(\d+)\.wav', wav_file)
                            wav_idx = int(match.group(1)) if match else sent_chunk_count
                            
                            try:
                                await asyncio.sleep(0.02)
                                
                                file_mtime = os.path.getmtime(wav_path)
                                cpp_write_time = datetime.fromtimestamp(file_mtime)
                                
                                audio_data, audio_sr = sf.read(wav_path)
                                
                                if len(audio_data) == 0:
                                    continue
                                
                                if first_chunk_time is None:
                                    first_chunk_time = (time.time() - generate_start_time) * 1000
                                    print(f"[â±ï¸ Generate éŸ³é¢‘é¦–å“] {first_chunk_time:.1f}ms [åŒå·¥]", flush=True)
                                
                                if audio_data.dtype != np.int16:
                                    audio_data = (audio_data * 32767).astype(np.int16)
                                wav_base64 = base64.b64encode(audio_data.tobytes()).decode('utf-8')
                                
                                chunk_duration = len(audio_data) / audio_sr
                                chunk_durations.append(chunk_duration)
                                
                                chunk_text = ""
                                if global_text_send_idx < len(global_parsed_texts):
                                    chunk_text = global_parsed_texts[global_text_send_idx]
                                    global_text_send_idx += 1
                                
                                chunk_data = {
                                    "chunk_idx": sent_chunk_count,
                                    "chunk_data": {
                                        "wav": wav_base64,
                                        "sample_rate": int(audio_sr)
                                    }
                                }
                                
                                send_time = time.time()
                                send_datetime = datetime.fromtimestamp(send_time)
                                write_to_send_delay_ms = (send_time - file_mtime) * 1000
                                interval_from_last_ms = (send_time - last_wav_send_time) * 1000 if last_wav_send_time else 0
                                last_wav_send_time = send_time
                                
                                init_wav_timing_log()
                                wav_timing_log_file.write(
                                    f"{wav_file:<20} "
                                    f"{cpp_write_time.strftime('%Y-%m-%d %H:%M:%S.%f')[:23]:<26} "
                                    f"{send_datetime.strftime('%Y-%m-%d %H:%M:%S.%f')[:23]:<26} "
                                    f"{write_to_send_delay_ms:>10.1f}ms    "
                                    f"{interval_from_last_ms:>10.1f}ms    "
                                    f"{chunk_duration:>6.3f}s\n"
                                )
                                wav_timing_log_file.flush()
                                
                                if chunk_text:
                                    chunk_data["chunk_data"]["text"] = chunk_text
                                    last_text_len += len(chunk_text)
                                    print(f"[WAV #{sent_chunk_count}] å‘é€ {wav_file} ({chunk_duration:.3f}s) + æ–‡æœ¬ | å»¶è¿Ÿ:{write_to_send_delay_ms:.0f}ms [åŒå·¥]", flush=True)
                                else:
                                    print(f"[WAV #{sent_chunk_count}] å‘é€ {wav_file} ({chunk_duration:.3f}s) | å»¶è¿Ÿ:{write_to_send_delay_ms:.0f}ms [åŒå·¥]", flush=True)
                                
                                await wav_queue.put(f"data: {json.dumps(chunk_data, ensure_ascii=False)}\n\n")
                                sent_chunk_count += 1
                                
                            except Exception as e:
                                print(f"[WAV #{wav_idx}] è¯»å–å¤±è´¥: {e} [åŒå·¥]", flush=True)
                        
                        await asyncio.sleep(scan_interval)
                        
                    except Exception as e:
                        print(f"[WAV Scanner] å¼‚å¸¸: {e} [åŒå·¥]", flush=True)
                        await asyncio.sleep(scan_interval)
                
                print(f"[WAV Scanner] åœæ­¢ï¼Œå·²å‘é€ {sent_chunk_count} chunks [åŒå·¥]", flush=True)
            
            wav_scanner_task = asyncio.create_task(wav_scanner_coroutine())
            
            http_start = time.time()
            async with http_client.stream(
                "POST",
                f"{CPP_SERVER_URL}/v1/stream/decode",
                json=cpp_request,
                timeout=600.0
            ) as response:
                http_connect_time = (time.time() - http_start) * 1000
                if http_connect_time > 50:
                    print(f"[Generate] âš ï¸ HTTPè¿æ¥å»¶è¿Ÿ: {http_connect_time:.0f}ms [åŒå·¥]", flush=True)
                
                if response.status_code != 200:
                    error_text = await response.aread()
                    print(f"[streaming_generate] C++ decode é”™è¯¯: {error_text.decode()} [åŒå·¥]", flush=True)
                    stop_wav_scanner.set()
                    wav_scanner_task.cancel()
                    yield f"data: {json.dumps({'error': 'decode failed'}, ensure_ascii=False)}\n\n"
                    return
                
                buffer = ""
                should_exit = False
                
                sse_iterator = response.aiter_text().__aiter__()
                
                while not should_exit:
                    if is_breaking:
                        print(f"[streaming_generate] æ£€æµ‹åˆ° break æ ‡å¿—ï¼Œåœæ­¢å‘é€æ•°æ® [åŒå·¥]", flush=True)
                        yield f"data: {json.dumps({'break': True, 'done': True, 'message': 'ç”¨æˆ·æ‰“æ–­'}, ensure_ascii=False)}\n\n"
                        should_exit = True
                        break
                    
                    try:
                        while True:
                            try:
                                wav_chunk = wav_queue.get_nowait()
                                yield wav_chunk
                            except asyncio.QueueEmpty:
                                break
                        
                        try:
                            chunk = await asyncio.wait_for(sse_iterator.__anext__(), timeout=0.1)
                            buffer += chunk
                        except asyncio.TimeoutError:
                            continue
                        except StopAsyncIteration:
                            break
                        
                        while "\n\n" in buffer or "\r\n\r\n" in buffer:
                            if "\r\n\r\n" in buffer:
                                event_str, buffer = buffer.split("\r\n\r\n", 1)
                            else:
                                event_str, buffer = buffer.split("\n\n", 1)
                            
                            for line in event_str.split("\n"):
                                line = line.strip()
                                if line.startswith("data: "):
                                    try:
                                        event_data = json.loads(line[6:])
                                        
                                        if 'is_listen' in event_data:
                                            new_is_listen = event_data['is_listen']
                                            if new_is_listen != is_listen:
                                                print(f"[streaming_generate] is_listen: {is_listen} -> {new_is_listen} [åŒå·¥]", flush=True)
                                                is_listen = new_is_listen
                                        
                                        if 'end_of_turn' in event_data:
                                            end_of_turn = event_data['end_of_turn']
                                            if end_of_turn:
                                                print(f"[streaming_generate] end_of_turn=True [åŒå·¥]", flush=True)
                                        
                                        if 'text' in event_data and event_data['text']:
                                            all_generated_text.append(event_data['text'])
                                            if first_text_time is None:
                                                first_text_time = (time.time() - generate_start_time) * 1000
                                                print(f"[streaming_generate] æ–‡æœ¬é¦–å“: {first_text_time:.1f}ms [åŒå·¥]", flush=True)
                                        
                                    except json.JSONDecodeError:
                                        pass
                            
                            while True:
                                try:
                                    wav_chunk = wav_queue.get_nowait()
                                    yield wav_chunk
                                except asyncio.QueueEmpty:
                                    break
                            
                            if is_listen:
                                # ğŸ”§ [ä¿®å¤éŸ³é¢‘é”™ä½] is_listen=True æ—¶ï¼Œå¿«é€Ÿæ£€æŸ¥æ˜¯å¦æœ‰æ®‹ç•™éŸ³é¢‘
                                # åŸé—®é¢˜ï¼šTTS å¼‚æ­¥å¤„ç†ï¼Œå¯èƒ½è¿˜æœ‰æœªå®Œæˆçš„éŸ³é¢‘
                                # è§£å†³ï¼šéé˜»å¡å¿«é€Ÿæ‰«æï¼Œæœ€å¤šç­‰å¾… 300msï¼Œæœ‰æ–°éŸ³é¢‘å°±å‘é€
                                quick_check_start = time.time()
                                quick_check_rounds = 0
                                while (time.time() - quick_check_start) < 0.05: # < 50ms
                                    quick_check_rounds += 1
                                    # æ£€æŸ¥é˜Ÿåˆ—ä¸­æ˜¯å¦æœ‰æ–°çš„ wav
                                    found_new = False
                                    while True:
                                        try:
                                            wav_chunk = wav_queue.get_nowait()
                                            yield wav_chunk
                                            found_new = True
                                        except asyncio.QueueEmpty:
                                            break
                                    if not found_new and quick_check_rounds >= 2:
                                        break
                                    await asyncio.sleep(0.02)
                                
                                print(f"[streaming_generate] is_listen=Trueï¼Œå·²å‘é€ {sent_chunk_count} chunks [åŒå·¥]", flush=True)
                                yield f"data: {json.dumps({'is_listen': True, 'chunks_received': sent_chunk_count}, ensure_ascii=False)}\n\n"
                                should_exit = True
                                break
                            
                            if end_of_turn:
                                print(f"[streaming_generate] end_of_turn=Trueï¼Œå·²å‘é€ {sent_chunk_count} chunks [åŒå·¥]", flush=True)
                                should_exit = True
                                break
                    
                    except Exception as e:
                        print(f"[streaming_generate] ä¸»å¾ªç¯å¼‚å¸¸: {e} [åŒå·¥]", flush=True)
                        break
                
                print(f"[streaming_generate] SSE æµç»“æŸï¼Œç­‰å¾… WAV æ‰«æå®Œæˆ... [åŒå·¥]", flush=True)
                max_final_wait = 3.0
                no_new_wav_count = 0
                final_start = time.time()
                
                while (time.time() - final_start) < max_final_wait:
                    prev_count = sent_chunk_count
                    
                    while True:
                        try:
                            wav_chunk = wav_queue.get_nowait()
                            yield wav_chunk
                        except asyncio.QueueEmpty:
                            break
                    
                    if sent_chunk_count > prev_count:
                        no_new_wav_count = 0
                    else:
                        no_new_wav_count += 1
                        if no_new_wav_count >= 10:
                            print(f"[streaming_generate] è¿ç»­ {no_new_wav_count} æ¬¡æ— æ–° WAVï¼Œç»“æŸæ‰«æ [åŒå·¥]", flush=True)
                            break
                    
                    await asyncio.sleep(0.1)
            
            stop_wav_scanner.set()
            try:
                await asyncio.wait_for(wav_scanner_task, timeout=1.0)
            except (asyncio.TimeoutError, asyncio.CancelledError):
                wav_scanner_task.cancel()
            
            if all_generated_text:
                full_text = "".join(all_generated_text)
                print(f"\n[ğŸ“ å®Œæ•´ç”Ÿæˆæ–‡æœ¬] {full_text}\n", flush=True)
            
            total_generate_time = (time.time() - generate_start_time) * 1000
            total_audio_duration = sum(chunk_durations) if chunk_durations else 0
            overall_rtf = total_generate_time / 1000 / total_audio_duration if total_audio_duration > 0 else 0
            
            print(f"\n{'='*60}", flush=True)
            print(f"[â±ï¸ Generate æ€§èƒ½æ€»ç»“] [åŒå·¥]", flush=True)
            print(f"  éŸ³é¢‘é¦–å“: {first_chunk_time:.1f}ms" if first_chunk_time else "  éŸ³é¢‘é¦–å“: N/A", flush=True)
            print(f"  æ€»ç”Ÿæˆæ—¶é—´: {total_generate_time:.1f}ms", flush=True)
            print(f"  æ€»éŸ³é¢‘æ—¶é•¿: {total_audio_duration:.2f}s", flush=True)
            print(f"  æ•´ä½“ RTF: {overall_rtf:.2f}x {'âœ…' if overall_rtf < 1.0 else 'âš ï¸'}", flush=True)
            print(f"  å‘é€ Chunk æ•°é‡: {sent_chunk_count}", flush=True)
            print(f"{'='*60}\n", flush=True)
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            print(f"[streaming_generate] å¼‚å¸¸: {e}\n{error_detail} [åŒå·¥]", flush=True)
            yield f"data: {json.dumps({'error': str(e)}, ensure_ascii=False)}\n\n"
        
        with session_lock:
            current_round_number += 1
            global_sent_wav_count = sent_chunk_count
            # ğŸ”§ [ä¿®å¤å¤šè½® user prompt] æ¯è½®ç»“æŸåé‡ç½® prefill è®¡æ•°å™¨
            # è¿™æ ·ä¸‹ä¸€è½®çš„ prefill ä¼šä» cnt=0 å¼€å§‹ï¼ŒC++ ç«¯èƒ½æ­£ç¡®è¯†åˆ«æ–°ä¸€è½®çš„å¼€å§‹
            global current_request_counter
            current_request_counter = 0
        
        print(f"[Generate] æœ¬è½®ç»“æŸï¼Œround_number={current_round_number}ï¼Œå·²å‘é€WAV={global_sent_wav_count} [åŒå·¥]", flush=True)
        
        # æ¨ç†ç»“æŸåï¼Œåœ¨åå°æ£€æŸ¥æ˜¾å­˜å¹¶åœ¨éœ€è¦æ—¶é‡å¯
        def background_memory_check():
            time.sleep(1.0)  # ç­‰å¾…ä¸€ä¼šå„¿è®©å½“å‰è¯·æ±‚å®Œå…¨ç»“æŸ
            if check_gpu_memory_and_restart_if_needed():
                print("[åŒå·¥] æ˜¾å­˜ä¸è¶³ï¼Œå·²åœ¨åå°è§¦å‘é‡å¯", flush=True)
        
        threading.Thread(target=background_memory_check, daemon=True).start()
        
        total_audio_duration = sum(chunk_durations) if chunk_durations else 0
        yield f"data: {json.dumps({'done': True, 'is_listen': is_listen, 'chunks_received': sent_chunk_count, 'audio_duration_seconds': total_audio_duration}, ensure_ascii=False)}\n\n"
    
    return StreamingResponse(
        generate_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
        }
    )


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="MiniCPMO C++ HTTP æœåŠ¡å™¨ï¼ˆç»Ÿä¸€ç‰ˆï¼šæ”¯æŒå•å·¥/åŒå·¥æ¨¡å¼åˆ‡æ¢ï¼‰")
    parser.add_argument("--host", type=str, default="0.0.0.0", help="æœåŠ¡å™¨åœ°å€")
    parser.add_argument("--port", type=int, default=8060, help="æœåŠ¡å™¨ç«¯å£")
    parser.add_argument("--llamacpp-root", type=str, default=LLAMACPP_ROOT, 
                        help="llama.cpp-omni æ ¹ç›®å½•ï¼ˆå¿…é¡»æŒ‡å®šï¼Œæˆ–è®¾ç½® LLAMACPP_ROOT ç¯å¢ƒå˜é‡ï¼‰")
    parser.add_argument("--model-dir", type=str, default=DEFAULT_MODEL_DIR, 
                        help="GGUF æ¨¡å‹ç›®å½•ï¼ˆå¿…é¡»æŒ‡å®šï¼Œæˆ–è®¾ç½® MODEL_DIR ç¯å¢ƒå˜é‡ï¼‰")
    parser.add_argument("--llm-model", type=str, default=DEFAULT_LLM_MODEL,
                        help="LLM æ¨¡å‹æ–‡ä»¶åï¼ˆå¯é€‰ï¼Œé»˜è®¤è‡ªåŠ¨ä» model-dir æ£€æµ‹ï¼‰")
    parser.add_argument("--gpu-devices", type=str, default=DEFAULT_GPU_DEVICES, help="GPU è®¾å¤‡ (e.g., '0,1')")
    parser.add_argument("--duplex", action="store_true", help="é»˜è®¤ä½¿ç”¨åŒå·¥æ¨¡å¼")
    parser.add_argument("--simplex", action="store_true", help="é»˜è®¤ä½¿ç”¨å•å·¥æ¨¡å¼ï¼ˆä¼˜å…ˆçº§é«˜äº --duplexï¼‰")
    parser.add_argument("--output-dir", type=str, default=None, 
                        help="C++ è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤åŸºäºç«¯å£å·: ./tools/omni/output_<port>ï¼‰")
    parser.add_argument("--vision-backend", type=str, default="metal", choices=["metal", "coreml"],
                        help="è§†è§‰ç¼–ç å™¨åç«¯: metal(é»˜è®¤GPU) æˆ– coreml(ANEåŠ é€Ÿï¼ŒmacOSä¸“ç”¨)")
    
    args = parser.parse_args()
    
    # ========== å‚æ•°éªŒè¯ ==========
    # 1. éªŒè¯ LLAMACPP_ROOT
    llamacpp_root = args.llamacpp_root
    if not llamacpp_root:
        print("âŒ é”™è¯¯: å¿…é¡»æŒ‡å®š --llamacpp-root æˆ–è®¾ç½® LLAMACPP_ROOT ç¯å¢ƒå˜é‡", flush=True)
        print("   ç¤ºä¾‹: python minicpmo_cpp_http_server.py --llamacpp-root /path/to/llama.cpp-omni --model-dir /path/to/gguf", flush=True)
        sys.exit(1)
    if not os.path.isdir(llamacpp_root):
        print(f"âŒ é”™è¯¯: LLAMACPP_ROOT ç›®å½•ä¸å­˜åœ¨: {llamacpp_root}", flush=True)
        sys.exit(1)
    # æ›´æ–°å…¨å±€å˜é‡
    LLAMACPP_ROOT = llamacpp_root
    
    # 2. éªŒè¯ MODEL_DIR
    model_dir = args.model_dir
    if not model_dir:
        print("âŒ é”™è¯¯: å¿…é¡»æŒ‡å®š --model-dir æˆ–è®¾ç½® MODEL_DIR ç¯å¢ƒå˜é‡", flush=True)
        print("   ç¤ºä¾‹: python minicpmo_cpp_http_server.py --llamacpp-root /path/to/llama.cpp-omni --model-dir /path/to/gguf", flush=True)
        sys.exit(1)
    if not os.path.isdir(model_dir):
        print(f"âŒ é”™è¯¯: MODEL_DIR ç›®å½•ä¸å­˜åœ¨: {model_dir}", flush=True)
        sys.exit(1)
    
    # 3. è‡ªåŠ¨æ£€æµ‹æˆ–éªŒè¯ LLM æ¨¡å‹
    llm_model = args.llm_model
    if not llm_model:
        llm_model = auto_detect_llm_model(model_dir)
        if llm_model:
            print(f"âœ… è‡ªåŠ¨æ£€æµ‹åˆ° LLM æ¨¡å‹: {llm_model}", flush=True)
        else:
            print(f"âŒ é”™è¯¯: åœ¨ {model_dir} ä¸­æœªæ‰¾åˆ° LLM GGUF æ¨¡å‹", flush=True)
            print("   è¯·ä½¿ç”¨ --llm-model æ‰‹åŠ¨æŒ‡å®šï¼Œæˆ–ç¡®ä¿ç›®å½•ä¸­æœ‰ .gguf æ–‡ä»¶", flush=True)
            sys.exit(1)
    else:
        llm_path = os.path.join(model_dir, llm_model)
        if not os.path.exists(llm_path):
            print(f"âŒ é”™è¯¯: LLM æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {llm_path}", flush=True)
            sys.exit(1)
    
    # æ›´æ–°å…¨å±€å˜é‡
    globals()['LLAMACPP_ROOT'] = llamacpp_root
    globals()['DEFAULT_LLM_MODEL'] = llm_model
    
    # 4. è®¾ç½®å‚è€ƒéŸ³é¢‘è·¯å¾„ï¼ˆå¦‚æœæœªæŒ‡å®šï¼‰
    if not globals()['FIXED_TIMBRE_PATH']:
        globals()['FIXED_TIMBRE_PATH'] = os.path.join(llamacpp_root, "tools/omni/assets/default_ref_audio.wav")
    FIXED_TIMBRE_PATH = globals()['FIXED_TIMBRE_PATH']
    
    # 5. è®¾ç½®è§†è§‰ç¼–ç å™¨åç«¯
    if args.vision_backend == "coreml":
        vision_coreml = os.path.join(model_dir, "vision", "coreml_minicpmo45_vit_all_f16.mlmodelc")
        if os.path.exists(vision_coreml):
            globals()['VISION_BACKEND'] = "coreml"
            print(f"âœ… Vision backend: CoreML/ANE ({vision_coreml})", flush=True)
        else:
            print(f"âš ï¸  CoreML model not found at {vision_coreml}, falling back to Metal", flush=True)
            globals()['VISION_BACKEND'] = "metal"
    else:
        globals()['VISION_BACKEND'] = "metal"
        print(f"âœ… Vision backend: Metal (GPU)", flush=True)
    VISION_BACKEND = globals()['VISION_BACKEND']
    
    # ç¡®å®šé»˜è®¤æ¨¡å¼ï¼š--simplex ä¼˜å…ˆçº§æœ€é«˜ï¼Œå¦åˆ™çœ‹ --duplex
    if args.simplex:
        default_duplex_mode = False
    elif args.duplex:
        default_duplex_mode = True
    else:
        default_duplex_mode = False  # é»˜è®¤å•å·¥
    
    # ğŸ”§ [å¤šå®ä¾‹æ”¯æŒ] è®¾ç½®è¾“å‡ºç›®å½•ï¼ˆåŸºäºç«¯å£å·ï¼Œé¿å…å¤šå®ä¾‹å†²çªï¼‰
    # ğŸ”§ [ä¿®å¤] ä½¿ç”¨ globals() æ›´æ–°å…¨å±€å˜é‡ï¼Œç¡®ä¿å…¶ä»–å‡½æ•°èƒ½è®¿é—®åˆ°
    if args.output_dir:
        globals()['CPP_OUTPUT_DIR'] = args.output_dir
    else:
        # é»˜è®¤åŸºäºç«¯å£å·åˆ›å»ºç‹¬ç«‹çš„è¾“å‡ºç›®å½•
        globals()['CPP_OUTPUT_DIR'] = os.path.join(llamacpp_root, f"tools/omni/output_{args.port}")
    CPP_OUTPUT_DIR = globals()['CPP_OUTPUT_DIR']
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(CPP_OUTPUT_DIR, exist_ok=True)
    
    app.state.port = args.port
    app.state.model_dir = model_dir
    app.state.gpu_devices = args.gpu_devices
    app.state.default_duplex_mode = default_duplex_mode
    app.state.output_dir = CPP_OUTPUT_DIR  # ä¿å­˜åˆ° app.state
    
    mode_name = "åŒå·¥" if default_duplex_mode else "å•å·¥"
    print(f"", flush=True)
    print(f"{'='*60}", flush=True)
    print(f"MiniCPM-o C++ HTTP æœåŠ¡å™¨", flush=True)
    print(f"{'='*60}", flush=True)
    print(f"  HTTP åœ°å€: http://{args.host}:{args.port}", flush=True)
    print(f"  å¥åº·æ£€æŸ¥: http://{args.host}:{args.port + 1}/health", flush=True)
    print(f"  é»˜è®¤æ¨¡å¼: {mode_name}", flush=True)
    print(f"", flush=True)
    print(f"  LLAMACPP_ROOT: {llamacpp_root}", flush=True)
    print(f"  MODEL_DIR:     {model_dir}", flush=True)
    print(f"  LLM_MODEL:     {llm_model}", flush=True)
    print(f"  OUTPUT_DIR:    {CPP_OUTPUT_DIR}", flush=True)
    print(f"  REF_AUDIO:     {FIXED_TIMBRE_PATH}", flush=True)
    print(f"  VISION_BACKEND: {VISION_BACKEND}", flush=True)
    print(f"{'='*60}", flush=True)
    print(f"", flush=True)
    
    uvicorn.run(app, host=args.host, port=args.port, workers=1)
